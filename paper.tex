\documentclass[10pt]{article}

% amsmath package, useful for mathematical formulas
\usepackage{amsmath}
% amssymb package, useful for mathematical symbols
\usepackage{amssymb}

% graphicx package, useful for including eps and pdf graphics
% include graphics with the command \includegraphics
\usepackage{graphicx}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

\usepackage{color} 

% Use doublespacing - comment out for single spacing
%\usepackage{setspace} 
%\doublespacing


% Text layout
\topmargin 0.0cm
\oddsidemargin 0.5cm
\evensidemargin 0.5cm
\textwidth 16cm 
\textheight 21cm

% Bold the 'Figure #' in the caption and separate it with a period
% Captions will be left justified
\usepackage[labelfont=bf,labelsep=period,justification=raggedright]{caption}

% Use the PLoS provided bibtex style
\bibliographystyle{PLoS2009}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother


% Leave date blank
\date{}

\pagestyle{myheadings}
%% ** EDIT HERE **
%% Please insert a running head of 30 characters or less.  
%% Include it twice, once between each set of braces
\markboth{Modeling structured RNA}{Modeling structured RNA}

%% ** EDIT HERE **
%% PLEASE INCLUDE ALL MACROS BELOW
\input{defs.tex}
%% END MACROS SECTION

\begin{document}

% Title must be 150 words or less
\begin{flushleft}
  {\Large
    \textbf{\titlestring}
  }
\\
\authorstring
\end{flushleft}

% figures in figs_plos:
% 1: parent.pdf
% 2: threeway.pdf
% 3: stree-with-structure.pdf
% 4: stree-mutations-with-structures.pdf
% 5: perfect.pdf
% 6: ama.pdf

% Please keep the abstract between 250 and 300 words
\newpage
\section*{Abstract}
The existence of an all-RNA primordial ribosome was proposed by
Francis Crick in 1968.  Recently, a domain-level model for the
original ribosome was proposed by Smith et al.  Given the abundance of
ribosomal RNA sequence data and the many successful reconstructions of
ancestral proteins, the reconstruction and synthesis of ancestral
ribosomes (and other RNAs) is a feasible goal for paleogenetics.  This
will require new bioinformatics tools and methods, in particular a
robust theoretical framework for reconstructing histories of
substitutions, indels and changes in RNA structure.

We describe a ``transducer composition'' algorithm for extending
pairwise probabilistic models of RNA structural evolution to models of
multiple sequences related by a phylogenetic tree.  This algorithm
draws on formal models of computational linguistics as well as the
1985 protosequence algorithm of David Sankoff.  The output of the
composition algorithm is a multiple-sequence stochastic context-free
grammar.  We describe dynamic programming algorithms, which are robust
to null cycles and empty bifurcations, for parsing this grammar.
Example applications include structural alignment of non-coding RNAs,
propagation of structural information from an
experimentally-characterized sequence to its homologs, and inference
of the ancestral structure of a set of diverged RNAs.

We implemented the above algorithms for a simple model of pairwise RNA structural evolution;
in particular the algorithms for maximum likelihood (ML) alignment of three known RNA structures an a known phylogeny
and inference of the common ancestral structure.
We compared this ML algorithm to a variety of related, but simpler, techniques,
including ML alignment algorithms for simpler models that omitted various aspects of the full model
and also a heuristic (sum-over-pairs) posterior-decoding alignment algorithm for one of the simpler models.

Our results suggest that ML algorithms incorporating basepair structure are the most likely to estimate the alignment perfectly.
However, the heuristic posterior-decoding algorithm scores higher on finer-grained alignment accuracy metrics.
Since the posterior-decoding heuristic is substantially faster than exact phylogenetic ML,
this further motivates the use of sum-over-pairs (and approximate sum-over-pairs) heuristics
for paleogenetics and other alignment problems.


% Please keep the Author Summary between 150 and 200 words
% Use first person. PLoS ONE authors please skip this step. 
% Author Summary not valid for PLoS ONE submissions.   
\newpage
\section*{Author Summary}

A number of leading methods for bioinformatics analysis of structural
RNAs use probabilistic grammars as models for pairs of homologous
RNAs.  We show that any such pairwise grammar can be extended to an
entire phylogeny by treating the pairwise grammar as a machine (a
``transducer'') that models a single ancestor-descendant relationship
in the tree, transforming one RNA structure into another.  In addition
to current applications such as RNA genefinding, homology detection,
alignment and secondary structure prediction, this should permit
probabilistic reconstruction of RNA genes ancestral to many
present-day sequences.  We describe algorithms, software
implementations, and an elementary benchmark of the dependence of the
accuracy of three-taxon RNA reconstruction on the outgroup branch
length.  In the Discussion we consider how the three-taxon RNA
alignment-reconstruction-folding algorithm, which is currently very
computationally-expensive, might be made more efficient so that larger
phylogenies could be considered.

\newpage
\section*{Introduction}
% Biological motivation
In 1968, Francis Crick hypothesized that the first ribosome consisted entirely of RNA, without any protein cofactors \cite{Crick68}.
A domain structure for this primeval ribosome was recently proposed \cite{SmithEtAl2008}.
To synthesize such a reconstructed ribosome or reconstructions of other evolutionarily significant RNAs
such as group II introns \cite{LehmannSchmidt2003} or telomerase \cite{AntalEtAl2002},
it will be necessary to develop methods that can predict the sequences
and structures of ancient RNAs
based on the divergent sequences of their many descendants.

% SCFGs for RNA
An inspection of RNA alignments, such as those in the \RFAM\ database
\cite{GriffithsJonesEtAl2003}, suggests that an evolutionary model for
RNA structure must eventually include multiple layers of detail: point
substitutions, covariant substitutions of base-pairs
\cite{HancockTautzDover88,LeontisEtAl2002}, indels
\cite{TakeshiTsutomu2008}, local changes in secondary structure such
as helix slippage \cite{HancockDover90}, and changes in domain
structure \cite{SmithEtAl2008}.  Stochastic context-free grammars
(SCFGs), which can efficiently detect the long-range correlations
of RNA base-pairing structures, are natural probabilistic models of such
phenomena and have been used for ncRNA homology detection
\cite{Eddy94,Durbin98,KleinEddy2003,NawrockiEddy2007}, gene prediction
\cite{RivasEddy99,PedersenEtAl2006}, folding
\cite{KnudsenHein2003,DowellEddy2004} and alignment
\cite{Holmes2005,DowellEddy2006,BradleyPachterHolmes2008}.

% Two parts: pairwise & multiple
By analogy with models of substitution processes, which are well-understood \cite{Felsenstein2003},
we may take the problem of building phylogenetic models of RNA evolution and split it into two halves.
The first half is the development of a {\bf pairwise model},
describing the probability distribution $P(Y|X)$ of a descendant ($Y$) conditional on its immediate ancestor ($X$).
In substitution processes, the pairwise model is a conditional substitution matrix.
Often (but not always) the pairwise model, representing a finite evolutionary time $T$,
is derived from an instantaneous model of change over an infinitesimal time interval,
i.e., a continuous-time Markov chain (parametrized by a rate matrix).
Obtaining the transition probabilities of this chain (via exponentiation of the rate matrix)
yields a pairwise model whose parameters are smoothly-varying functions of $T$.
A pairwise model represents an individual branch of a phylogenetic tree, with $T$ representing the length of that branch.

% (second part: multiple)
The second half of the phylogenetic modeling problem involves extending the model (and related inference algorithms) from a single branch to a complete phylogeny,
i.e., from a pairwise model of two sequences to a {\bf multiple-sequence model} of many sequences.
In a typical situation, the sequences at the leaves of the tree are
observed but those at internal nodes are not.
Questions of interest then include:
\begin{description}
\item[A.] What is the likelihood for the observed sequence data?
\item[B.] Can we sample (find the mode, take moments, etc.) from the posterior distribution of the unobserved sequence at the root node?
\item[C.] Can we sample from the posterior of the unobserved sequences at the other internal nodes?
\item[D.] Can we estimate summaries of the evolutionary history, such as
  the number of substitution events on each branch (for a substitution
  model), the alignment (for a model which includes indels), or
  changes in the underlying structure (for a model of RNA structure)?
\end{description}

For substitution models, there has been extensive work focused on answering each of these questions.
Given a pairwise substitution model, questions A and B can be
answered exactly by Felsenstein's pruning algorithm
\cite{Felsenstein81} and question C can be answered by the peeling
algorithm (first presented for pedigree analysis by Elston and Stewart \cite{ElstonStewart71}).
The estimation of evolutionary histories (question D) has been
addressed by exact summarization \cite{HolmesRubin2002b} and sampling
\cite{Nielsen2001} approaches.
Another representation of answers A-C
is that the pruning and peeling algorithms (combined) are just
the sum-product algorithm on a directed graphical model \cite{Pearl82},
yielding exact marginal distributions for unobserved variables.
Graphical models also suggest general-purpose sampling approaches
in addition to the exact sum-product algorithm.

% We want a multiple SCFG. Not a pairwise SCFG...
The two halves of the reconstruction problem --- developing a pairwise model and then extending it to multiple sequences --- are largely independent.
Felsenstein's pruning algorithm, for example, is essentially blind to the parametric form of the pairwise substitution model;
it just assumes that a substitution matrix is provided for every branch.
Subsequent models developed by other researchers can be plugged into the pruning algorithm without modification \cite{Yang94b,WhelanGoldman2001}.

We therefore addressed the problem of modeling the indel-evolution of
multiple structured RNAs in a similarly-modular fashion by separating
the creation of pairwise and multiple-sequence models.  In previous
work, we addressed the first (pairwise) part of the RNA reconstruction
problem by describing a simple continuous-time model of RNA structural
evolution \cite{Holmes2004}.  This model corresponded to a Pair SCFG
with a time-dependent parametrization which we used to
simultaneously align and predict the structure of
pairs of related RNAs.  The focus of the present work is to solve the second
(multiple-sequence) part of the RNA reconstruction problem by giving a
general procedure for extending a pairwise model to multiple
sequences related by a phylogenetic tree.  This process
yields a multiple-sequence SCFG, a natural model of the evolutionary
relationships between multiple structured RNAs.
% (just as a Pair SCFG is the natural model of the relationship between two RNAs).

The main contributions of this paper are
(1) an algorithm that transforms a phylogenetic ensemble of pair
grammars, representing models on branches of a phylogenetic tree,
into a coherent, multiple-sequence SCFG,
(2) dynamic programming (DP) algorithms for performing inference under
this multiple-sequence SCFG, and
% (which appear to converge even if the SCFG contains null bifurcations and null cycles);
(3) freely-available software implementing algorithms (1) and (2) for
the simplified case of a three-taxon star-topology tree.
While the idea of composing conditionally-normalized models on trees
is intuitive, the resulting models can be very complex, even for
simple models of RNA evolution, making (1) necessary.
Studies of related indel models have suggested that an implementation
of dynamic programming (DP) algorithms on a three-taxon tree is sufficient to
draw samples from the posterior distribution of ancestral sequences on
more complex tree topologies, using Markov Chain Monte Carlo or MCMC
\cite{HolmesBruno2001,JensenHein2002,RedelingsSuchard2005},
suggesting that (2) and (3) are, in principle, sufficient for analyzing trees
relating many sequences.

% Benchmarking
We show that our algorithm produces a multiple-sequence grammar which is
much more compact than suggested by naive approaches to model
construction.  We provide analyses of the asymptotic complexities of
models constructed using our procedure and provide estimates of the
time and memory required to reconstruct the structures of several RNA
families for the case of a three-taxon phylogeny, which we have
implemented in the program \indiegram. While by these estimates only
the smallest sequences currently fit into affordable memory, thereby
preventing us from applying our method to many problems of interest,
a simulation study suggests that we can hope to accurately reconstruct
ancestral structures over long evolutionary time, even in the presence
of structural divergence.

In the Discussion, we speculate on algorithmic extensions that
may reduce memory requirements, inspired by related work in
reconstructing DNA and protein sequences.

% Furthermore, we report benchmark results for special cases that can fit into memory:
% (1) the accuracy of reconstruction for the case where indels are prohibited and alignment is constrained, and
% (2) the case where we build a progressive multiple sequence alignment using pairwise comparisons.


\newpage
\section*{Methods}
We describe below a general method for constructing a multiple-sequence
stochastic grammar for alignment, folding and ancestral reconstruction of RNA,
given a phylogenetic tree and a description of the evolutionary
process acting along each branch.

% Functional constraints on structured RNA act largely at the level of
% secondary structure, so a realistic model of RNA evolution must model
% phenomena such as covariant
% base-pair substitutions or indels which preserve stem structures but
% modify stem length.
% Pair SCFGs---generative formal grammars or stochastic
% models of two sequences---can model these phenomena and serve as efficient models
% for RNA alignment and structure-prediction algorithms
% \cite{Holmes2005,DowellEddy2006,KiryuEtAl2007,BradleyPachterHolmes2008}.
% 
% Our method for generating a multiple-sequence model is qualitatively
% similar to the method presented in \cite{Holmes2003} for HMMs, but
% modified to permit bifurcations and covariant substitutions as modeled
% by SCFGs. Grammars constructed by this algorithm can be used to infer
% probable structures of ancestral RNAs.


\subsection*{Overview}

Our problem statement is this:
%\vspace{.5\baselineskip}
%\fbox{
%\parbox{.8\textwidth}
\textbf{Given a phylogenetic tree relating several structured RNAs and a
  description of the evolution of a structured RNA
  along a single branch of the tree (in the form of a Pair SCFG),
  (1) find the corresponding
  phylogenetic multiple-sequence grammar and (2) use that grammar to
  reconstruct, {\em a posteriori}, the evolutionary histories of the
  RNAs.}
%}
%\vspace{.5\baselineskip}
We assume here that the phylogeny, including both the tree topology
and branch lengths, is given.
% Ian, I moved the bits which you added here to the discussion; please
% edit per your discretion.

This paper focuses on model construction and inference algorithms
rather than the heuristics which will be necessary to make these
algorithms fast enough for analysis of many biological datasets.
As discussed below, the complexity of general inference algorithms is
prohibitively high for many problems of interest.
However, this complexity can be significantly
reduced by incorporating outside knowledge.  For example, if we know
the consensus structure of several sequences or their individual
structures, then we can constrain our algorithms accordingly.
Similarly, we might consider only ancestral structures which are
compatible with a given multiple sequence alignment, or a relatively small set of candidate alignments (as in the ORTHEUS program \cite{PatenHolmesBirney2008}). 
Such constraints are
commonly used by programs for SCFG-based RNA sequence analysis such as QRNA \cite{RivasEddy2001}, \stemloc\ \cite{Holmes2005} and CONSAN \cite{DowellEddy2006}.
Alignment and structural constraints can be combined \cite{Holmes2005}.


In the following sections we introduce more precise definitions for two-sequence
models of RNA structure and outline our algorithms for
(1) combining these two-sequence models on a phylogenetic tree and
(2) using the composite phylogenetic grammars for inference.

% To generalize from two sequences to many sequences,
% we place a parse-tree transducer on every branch of a phylogenetic tree.


\subsection*{Two-sequence models} \seclabel{twoseq}

We discuss the general problem of creating state-space models of the
evolution of related sequences, beginning with models of substitution processes acting at independent
sites (as studied in likelihood phylogenetics) and generalizing to models of
indels, first in primary sequences and then in sequences with
conserved secondary structure.

A stochastic model for the evolution of one sequence (the ancestor, $X$) into
another (the descendant, $Y$) over an interval of time ($T$) can be described by a
joint distribution, $P (X, Y | T)$.
This joint distribution can be factored, $P (X) \cdot P (Y | X, T)$, 
where $P(X)$ is the marginal distribution over ancestral sequences
and $P(Y | X, T)$ is the conditional distribution over descendant sequences given an ancestral sequence.
In terms of phylogenetics, the conditional distribution $P(Y | X, T)$ describes the evolution $X \stackrel{T}{\to} Y$
along a branch of length $T$.

It is possible to ``multiply'' two such models together.
More precisely, one multiplies two conditional distributions and sums out the intermediate sequence.
Thus, successive evolution along two branches $X \stackrel{T_1}{\to} Y \stackrel{T_2}{\to} Z$
is modeled by the distribution
\[
P(Y,Z|X,T_1,T_2) = P(Y | X, T_1) P(Z | Y, T_2)
\]

and we can sum sequence $Y$ out of this, obtaining the distribution
\[
P(Z|X,T_1+T_2) = \sum_Y P(Y | X, T_1) P(Z | Y, T_2)
\]
for the composite branch
$X \stackrel{T_1 + T_2}{\longrightarrow} Z$.

This formalism underlies likelihood phylogenetics.
Working under the independent-sites assumption, $P (X, Y | T)$ is the $(X,Y)$'th element of the joint substitution matrix for a single site
and $P(Y | X, T)$ is the corresponding element of the conditional matrix.
The conditional matrix is in fact the matrix exponential
 $\exp({\bf R}T)$, where ${\bf R}$ is the substitution rate matrix \cite{HolmesRubin2002b}.
Composition of two branches just amounts to a matrix multiplication.

A similar formalism can be used to describe the evolution of whole
sequences with indels.
Suppose that the joint distribution $P (X, Y | T)$ is the distribution
modeled by a pair hidden Markov model (Pair HMM) \cite{Durbin98},
a probabilistic model of the evolution of two sequences under the
approximation that only adjacent characters are directly correlated,
and the marginal $P(X)$ is the distribution of a single-sequence HMM,
a probabilistic model of single sequences under the same approximation.
The conditional distribution $P(Y | X, T)$ then corresponds to a conditional Pair HMM,
a discrete-state machine which transforms one sequence (the input, $X$) into another (the output, $Y$).
Following computational linguists, we call this conditionally-normalized state machine a
 {\bf string transducer} or simply a {\bf transducer}
\cite{BradleyHolmes2007}.
Because of its conditional normalization, this state machine is
distinct from a standard Pair HMM.
A Pair HMM has two outputs $X$ and $Y$ and emits symbols to both of those outputs,
while a transducer absorbs symbols from the input $X$ and emits
symbols to the output $Y$.
Despite this distinction, Pair HMMs and transducers share very similar inference algorithms;
for example, $P(Y | X, T)$ is computed using a direct analogue of the Forward algorithm \cite{Durbin98}.

We extend this formalism to the case of structured RNA as follows.
Let $X$ and $Y$ now represent structured RNA sequences or, more
precisely, parse trees.
A single-sequence SCFG models the marginal $P(X)$;
a jointly-normalized Pair SCFG \cite{Durbin98} models the the joint distribution $P (X, Y | T)$.
The conditional distribution $P(Y | X, T)$ is modeled by a conditionally-normalized Pair SCFG.
Following terminology from computational linguistics
\cite{ComonEtAl2007-TreeTransducers}, we call this
conditionally-normalized grammar a {\bf parse-tree transducer}.

String transducers are special cases of parse-tree transducers, just
as HMMs are special cases of SCFGs.
Henceforth, we will drop the distinction between strings and parse trees.
We will also refer interchangeably to ``states'' (in the state-machine representation)
and ``nonterminals'' (in the grammar representation).
Likewise, we will refer interchangeably to ``state paths'' (machines) and ``parse trees'' (grammars).


\paragraph{Terminology and normalization.}

Consider the stochastic grammar which generates parse trees from the marginal distribution $P(X)$.
It is convenient to represent this grammar as a transducer whose input is constrained to be null,
i.e. a machine that accepts a dummy (empty) input sequence, and outputs sequence $X$.
We refer to this as the {\bf singlet transducer}.
In contrast, the more general type of transducer that absorbs parse trees $X$ and generates modified parse trees $Y$ from the conditional distribution $P(Y | X, T)$ is a {\bf branch transducer}.
By definition, singlet transducers only emit symbols to their output sequence, and use a restricted set of state types.
Branch transducers, in contrast, can both emit symbols to their outputs and absorb symbols from their inputs, and so use the full range of state types.

Transducers can have states of type $\Sstart$, $\Send$,
$\Swait$, $\Sinsert$ and $\Smatch$.
The first three state types, $\Sstart$, $\Send$ and $\Swait$, are null:
they do not emit or absorb any symbols and are required solely for
organizational purposes (see following section).
Two types of states can emit and/or absorb symbols, $\Sinsert$ and $\Smatch$.
An $\Sinsert$ state emits a symbol to the output without absorbing anything.
A $\Smatch$ state absorbs a symbol on the input and either emits
the same symbol to the output, substitutes a different output symbol,
or emits no output symbol at all, the last corresponding to a deletion.

As stated above, the Pair SCFG must be conditionally normalized
so that models can be chained together,
extending the pairwise model to multiple sequences.
The transformation rules are partitioned into co-normalized groups;
within each group, the rule probabilities must sum to one.
In a jointly-normalized Pair SCFG, each group corresponds to the set of all rules that can be applied to a given nonterminal
(i.e., all outgoing transitions from a particular state).
In a conditionally-normalized Pair SCFG, in contrast,
each co-normalized group includes all rules that can be applied to a
given nonterminal {\em for a given set of absorbed symbols}.
%(In practice it is often expedient to relax these normalization guidelines somewhat,
%while preserving the overall probabilistic normalization over output parse trees.
%For example, the normalization of states $B$ and $B_p$ in \tabref{tkfstbranch} occurs on transitions into, rather than out of, those states.)

% Conditional normalization is required so that models can be chained together,
% extending the pairwise model to multiple sequences.
% In the language of graphical models, the jointly-normalized Pair SCFG represents an undirected
% edge in the model, whereas the conditionally-normalized SCFG represents a
% directed edge.  The rooted phylogeny which is input to our algorithm
% is a directed graphical model and so we require the conditional normalization.


\subsection*{Multiple-sequence models}

We can use the concepts of factoring probability distributions introduced in the two-sequence
framework to model the common descent of many homologous sequences.
Given a phylogenetic tree and a two-sequence model, we wish to obtain a
multiple-sequence SCFG describing the common descent of the observed sequences.

% We begin with some technical definitions and rules for combining models,
% then proceed to a more colloquial description of the collective behavior
% of a phylogenetic ensemble of transducers co-ordinated by these rules.

% Consider a phylogenetic tree relating $n$ structured RNAs
% $\{ X_1 , ... , X_n \}$ lying on the leaves of the tree,
% and a further $m$ ancestral RNAs
% $\{ X_{n+1} , ... , X_{n+m} \}$
% lying at the internal nodes of the tree.
% Because any node of the tree is independent of its sibling node conditioned on their common parent,
% we can factor the probability distribution $P(X_1 , ... , X_{n+m})$ into terms of the form
% $P(X_i | X_j, T)$, precisely the conditional distribution which is generated by a branch transducer.
% This has a ready biological interpretation:  A branch transducer
% evolves a sequence (and structure) along a branch of a phylogenetic tree,
% so we extend the two-sequence models just described to evolutionary models of many sequences
% by composing branch transducers on the branches of the tree.

A singlet transducer (which emits, but does not absorb, symbols) lies at the root of the phylogeny and 
serves as a generative model of the ancestral sequence.
To represent the evolution of an ancestral sequence into many descendant sequences,
we place a branch transducer on each branch of the phylogeny.
Figures \ref{fig:parent} and \ref{fig:threeway} show simple examples
of building a model to represent such an evolution.

Throughout this paper we frequently refer to two and
three-taxon (star) phylogenies.  In all cases, the sequence $W$ is
assumed to be the (unobserved) ancestral sequence and the sequences
$X$, $Y$, and $Z$ the (observed) extant sequences (as in Figures
\ref{fig:parent} and \ref{fig:threeway}).




\subsubsection*{The composition algorithm}

While this composition of conditionally-normalized models on a
phylogenetic tree is intuitive, in practice building such an ensemble
model is challenging due to the sheer number of possible states and
transitions of the ensemble model.
The maximum possible state space of the ensemble is the Cartesian product of the
individual transducer state spaces. If the singlet transducer has $a$
states, each branch transducer has $b$ states, and the phylogeny has $N$
branches, then an upper bound on the number of
ensemble states is $O(a \cdot b^N)$.
However, in practice there are many fewer states than suggested by
this bound; many state configurations are not reachable.  For example,
for the tree with two extant sequences and a single parent,
the branch transducers above leaves $X$ and $Y$ cannot simultaneously
be in $\Sinsert$ states, as this would correspond to aligning
non-homologous (inserted) characters.
Similarly, while an upper bound on the number of possible transitions
in the transition matrix of the ensemble model is $O((a \cdot b^N)^2)$,
in practice models never reach this bound,
due both to inaccessible configurations, such as the one described above,
and the sparseness of transitions between the remaining, accessible configurations.

While the accessible state space of the ensemble is smaller than that
given by the exponential upper bound, it is generally nonetheless too
complex to deal with by hand.
For example, the simple model of RNA structural evolution described in
Results yields an ensemble model of three sequences with 230 states
and 1,789 transitions.  More realistic models of RNA give rise to even
larger ensemble models.

We therefore need an algorithm to efficiently construct the state graph of the
ensemble model, consisting of a list of accessible states and the
possible transitions between them. 
By analogy with algorithms for uninformed graph search in artificial
intelligence, the transition graph of the ensemble can be constructed
by an uninformed depth-first search, where at each step of the search
we obtain the next possible ensemble states by changing the state of one or
more of the singlet or branch transducers. Beginning with the entire
ensemble in state $\Sstart$, the depth-first search of states
continues until all nodes are in state $\Send$.

The allowed transitions of the ensemble can be categorized as follows:
\begin{description}
\item[{\bf Null Transition}:]
  A branch transducer makes a transition into a $\Swait$ state, with no terminal emission or bifurcation.
\item[{\bf Terminal Emission}:]
  A singlet or branch transducer makes a transition into a state of type $\Sinsert$,
  emitting left and/or right terminal symbols (e.g., a single base or base-pair).
  These symbols are absorbed by the immediately-descended transducers,
  which are pushed into states of type $\Smatch$
  and may themselves emit terminal symbols
  that will be absorbed by {\em their} descendant transducers.
  This continues down the tree: The terminal symbols are passed from parents to children to grandchildren
  (albeit possibly being replaced by other terminal symbols as they
  are propagated down)
  and they propel branch transducers into $\Smatch$ states as they go.
  Eventually, the cascade of emitted terminal symbols stops when all the symbols have been deleted
  or when the cascade reaches the leaves of the tree.
\item[{\bf Bifurcation}:]
  A singlet or branch transducer makes a transition into a state of type $\Sinsert$ that spawns
  left and/or right nonterminal states.
  These nonterminals are processed recursively down the tree, just as in a
  terminal emission (conceptually, a bifurcation is a ``nonterminal emission'').
  As with terminal emissions, absorption of nonterminal emissions propels
  descendant transducers into $\Smatch$ states,
  making transitions which may themselves propagate nonterminals
  further down the tree.
  A biologically-relevant example of a bifurcation is the insertion of a stem
  into an ancestral RNA structure,
  which may then be conserved or deleted in the descendant structures.
\item[{\bf End Transition}:]
  The singlet transducer at the root makes a transition to the $\Send$ state,
  pushing all the descendant branch transducers into $\Send$ states and
  terminating the current branch of the parse tree.
\end{description}

Co-ordination between the various branch machines is achieved by
specifying an ordering on the nodes and by having branch transducers pause in $\Swait$
states while waiting to absorb a symbol from the node above.  
Only one transducer is allowed to make a spontaneous transition at a
time. If this transition corresponds to a terminal
emission or a bifurcation, then this may force descendant transducers
into making reactive transitions.

The four types of allowed transitions listed above can be formalized
as follows.
Let the total order on the nodes correspond to any preorder traversal of
the tree; thus, ``$m$ is ancestral to $n$'' is sufficient-but-not-necessary for ``$m \prec n$.''
Let ${\cal T}_m$ denote the singlet or branch transducer which emits symbols to node $m$.
Transducer ${\cal T}_m$ changes state if and only if one of the
following three mutually-exclusive conditions holds:
\begin{description}
\item{Type 1:} Transducer ${\cal T}_m$ is not in a $\Swait$ state,
  while all its successor transducers ${\cal T}_n$ are in $\Swait$
  states (where $m \prec n$).  ${\cal T}_m$ is free to make any transition.
\item{Type 2:} Transducer ${\cal T}_m$ is in a $\Swait$ state. Its parent transducer enters a $\Smatch$ or $\Sinsert$ state, emitting a symbol and forcing ${\cal T}_m$ into a $\Smatch$ state so it can absorb that symbol.
\item{Type 3:} Transducer ${\cal T}_m$ is in a $\Swait$ state. Its parent transducer enters the $\Send$ state, forcing ${\cal T}_m$ into the $\Send$ state as well.
\end{description}

A notational prescription for the allowed transitions may be found in \supptext{1}.

\subsubsection*{How the ensemble generates multiple alignments}

The possible transitions of the ensemble generate multiple alignments as follows:
\begin{enumerate}
\item
  The singlet transducer and all branch transducers begin in their respective $\Sstart$ states.
\item \label{item:InitialWindback}
  Before any residues can appear at the root, the branch transducers all wind back into $\Swait$ states,
  via type-1 transitions. This occurs in reverse order (i.e.,a postorder traversal of the tree).
\item During this initial windback, clade-specific insertions can occur.
  This process is described in detail at step \ref{item:CladeInsertion}.
\item \label{item:SingletStart}
  With all the branch transducers wound back into $\Swait$ states,
  the singlet transducer makes a (type-1) transition into an $\Sinsert$ state, emitting a symbol to the sequence at the root node.
\item The transducers on outgoing branches from the root then make (type-2) transitions into $\Smatch$ states,
  either copying the root symbol to their own outputs,
  substituting it for a different symbol or staying silent (this silence corresponds to a clade-specific deletion;
  in our formalism, both substitutions and deletions are handled by $\Smatch$ states.)
\item The transducers on branches one step away from the root then process the symbols which reached them
  (if any did), followed by transducers on branches two steps away from the root, then three steps, and so on
  (these can all be regarded as occurring simultaneously, in a single cascading wave of emissions).
\item \label{item:Windback}
  Eventually the emitted symbols are propagated, via type-2 transitions,
  all the way to the tips of the tree (if they survived)
  or to the nodes where they were deleted (if they did not survive).
  The wave of type-2 transitions has left a lot of branch transducers in $\Sinsert$ and $\Smatch$ states.
\item The branch transducers then, in postorder, each wind back into $\Swait$ states, just as at step \ref{item:InitialWindback}.
  (These windback transitions can be collapsed into a single ensemble transition, as with the emission cascade;
  however, the windback may be interrupted by clade-specific insertions; see below.)
\item \label{item:CladeInsertion}
  During the postorder windback, each branch transducer gets an opportunity to generate a new symbol (via type-1 transitions to $\Sinsert$ states).
  (If such a transition to $\Sinsert$ occurs, it corresponds to a clade-specific insertion.
  This insertion is propagated down the tree via a wave of type-2 transitions, as above,
  then we go back to step \ref{item:Windback}.)
\item Eventually, the entire ensemble has wound back, so that every transducer is in a $\Swait$ state except the singlet transducer at the root,
  which is still in an $\Sinsert$ state.
  At this point, all clade-specific insertions have been processed.
\item The singlet transducer now makes another type-1 transition.
  If this transition is to an $\Sinsert$ state, the entire cycle begins again: the singlet transducer emits the next symbol at the root,
  and we go back to step \ref{item:SingletStart}.
\item If, on the other hand, the singlet transducer enters its $\Send$ state,
  then a wave of type-3 transitions drives all the branch transducers into their respective $\Send$ states too,
  bringing the entire ensemble to a halt.
\end{enumerate}

\subsubsection*{Complexity of the transducer ensemble}

The total sizes of both the state space and the transition matrix are,
in general, dramatically smaller than implied by the exponential upper
bounds of $O(a \cdot b^N)$ and $O((a \cdot b^N)^2)$.  While we do not
have provable bounds on the size of the state space, we have observed
that the size of the state space is roughly linear in the number of
branches, $O(a \cdot b \cdot N)$, and the number of transitions is
approximately linear in the number of states for several pairwise models,
including the pairwise model which we use here.
However, these empirical observations are based on a
limited class of pairwise models and we do not have theoretical results for
how they will generalize to other pairwise models.  We do believe, however,
that the worst-case exponential bound will be avoided by (1)
omitting inaccessible state configurations and (2) eliminating
null windback states as described in the following section (which we
believe will prevent affine gap penalties from generating exponential
growth in the number of states).

Therefore, for the models which we have characterized, the search
algorithm given above for enumerating all allowed transitions of the
ensemble model typically generates $O(b)$ transitions from any given
state, thereby creating a very sparse transition matrix of size $O(a \cdot b^2 \cdot N)$.



\subsection*{Inference algorithms for multiple-sequence models}

In this section, we describe dynamic programming (DP) algorithms for
inferring the alignment, structure and evolutionary history
of multiple related RNAs, using the multiple-sequence SCFG we have derived.

The transducer composition algorithm described above constructs a phylogenetic SCFG
for both ancestral and extant sequences.
A parse tree for this SCFG represents a structural and evolutionary
explanation of the extant sequences, including a complete ancestral reconstruction.
Consequently, given a set of extant sequences, many of the questions of interest to us
can be reduced to searches over, or summarizations of, the set of possible parse trees.

Well-known algorithms already exist for maxing or summing over SCFG parse tree likelihoods.
The Cocke-Younger-Kasami (CYK) algorithm performs maximum-likelihood (ML) inference;
the Inside algorithm can be used to sum over parse trees or sample them {\em a posteriori};
and the Inside-Outside algorithm yields posterior probabilities for individual parse tree nodes \cite{Durbin98}.

All of these algorithms are, however, complicated (at least in our models) by
the existence of ``null cycles'' in the grammar.
A null cycle is a parse tree fragment that is redundant and could be removed, such as a detour through $\Snull$ states ($A \to X \to Y \to X \to Y \to B$)
that could be replaced by a direct transition ($A \to B$).
Biologically, null cycles correspond to fragments of ancestral sequence that were universally deleted and therefore
are unobserved in any of the extant sequences.
These unobserved fragments can be unbounded in length (and so, therefore, can the parse tree).
Within the CYK, Inside and Outside recursions, this causes cyclic dependencies which cannot be resolved.

Below we describe a method to eliminate null cycles from
the ensemble model by transforming any SCFG to an equivalent acyclic SCFG.
We then present multiple-sequence versions of the CYK, Inside and Outside algorithms.

While some sort of null-cycle elimination is often required in order
to deal with cyclic dependencies, there are several ways to accomplish
this other than the algorithm presented below.  A simpler approach
(that only works for the CYK algorithm) appears in the computational
linguistics literature \cite{GecsegSteinby97}.  We have also developed
a heuristic for CYK that simply ignores null cycles as well as an
iterative approximation that loops several times over
cyclically-dependent cells of the DP matrix until the estimate starts
to converge. For conciseness, we have omitted descriptions of these
methods, presenting only the exact elimination algorithm.


\subsubsection*{Exact elimination of null cycles in SCFGs}

As noted above, the ensemble grammar contains many rules that can be applied redundantly,
together or in isolation, to generate subtrees of the parse tree that do
not generate any terminals.
This generates cyclic dependencies in the standard DP recursions for inference.
In this subsection, we describe how to transform the SCFG so as to eliminate such redundant rules, yielding strictly acyclic DP recursions.
This transformation can be applied to any SCFG so as to remove null states and/or bifurcations:
the procedure is not restricted to grammars that were generated using our transducer composition algorithm.

We begin by identifying two distinct classes of redundant parse-subtree: {\bf empty bifurcations} and {\bf empty paths}.
We will eliminate each of these in turn.

An {\bf empty bifurcation} occurs when a child branch of a bifurcation state
transitions to the $\Send$ state without emitting any symbols and can
be removed from the model by creating an effective direct transition
encapsulating the empty bifurcation.  For
example, we can create an effective direct transition $N_1 \rightarrow
N_3$ between null states $N_1$ and $N_3$ in place of the empty
parse-subtree $N_1 \rightarrow B \rightarrow (N_2 \,\, N_3) \rightarrow
(End \,\, N_3)$, where $B$ is a bifurcation state with children $(N_2
\,\, N_3)$. Bifurcation states are the most computationally-costly
part of our models, so it is important to eliminate as many as
possible without reducing model expressiveness.

In contrast, an {\bf empty path} is defined as any parse-subtree {\em without} bifurcations that does not emit terminal symbols.
If $\Semit$ states $E_1$ and $E_2$ are connected in the state
graph via $\Snull$ states $N_1$ and $N_2$, then the path $E_1
\rightarrow N_1 \rightarrow N_2 \rightarrow E_2$ with  probability
$P(E_1 \rightarrow N_1) \cdot P(N_1 \rightarrow N_2) \cdot P(N_2
\rightarrow E_2)$ can be replaced by a single direct transition $E_1 \rightarrow
E_2$ with an identical probability.

% In practice, eliminating windback
% states reduces the size of the state space by $\simeq 20\%$, resulting
% in a significant reduction in memory needed. However, eliminating
% $\Snull$ states can increase the number of transitions in the model,
% so this reduction in memory usage comes at the cost of a small
% increase in runtime.

Empty paths occur in Hidden Markov Models (which are special cases of SCFGs)
and independent-sites models (which can be viewed as special cases of HMMs).
Conceptually, empty paths can represent histories that are valid
according to the model but cannot be resolved by direct observation.
Such null events can be real (e.g., ancestral residues that have been deleted in all extant lineages)
or they can be artefactual (e.g., transitions between placeholder null states of an HMM).

In our composite model, empty paths occur whenever a series of branch transducers winds back into $\Swait$ states.
Empty bifurcations occur when an entire substructure, present in an ancestor, is deleted in all that ancestor's extant descendants.

Empty paths and empty bifurcations are problematic because they can be combined to give finite-probability sequences of rules
that transform a nonterminal back into itself, with no observable emissions.
We refer to such sequences of rules as {\bf null cycles}.
As noted, null cycles generate cyclic dependencies in the CYK, Inside \& Outside algorithms.
Our goal is an algorithmic procedure to resolve these dependencies and account for the likelihood of such cycles by exact marginalization.

For simpler models, solutions to this problem are published.
Missing (empty) columns in independent-sites models can be accounted for by applying a correction factor $(1-p)^{-1}$
to account for the proportion of columns $p$ that are unobserved \cite{RivasEddy2008}.
The slightly more complicated situation of missing emissions in a HMM can be dealt with by
summing over all empty paths, yielding a geometric series that is solvable by matrix inversion
\cite{Holmes2003,Holmes2007,Lunter2007}.
Such algorithms
%, implemented by programs such as PhyloComposer \cite{Holmes2003,Holmes2007} and HMMoC \cite{Lunter2007},
effectively replace the HMM
with another HMM that contains no null cycles but is equivalent to the original, in that it models the
same probability distribution over sequences.
%The ``wing retraction'' algorithms used in the repetitively structured profile HMMs of HMMER \cite{hmmer} appear similar in operation.
However, these solutions do not easily generalize to SCFGs
(which may have empty bifurcations as well as empty paths).

\supptext{2}\ includes a complete formal algorithm for exact null-cycle elimination in SCFGs,
along with procedures for probabilistically restoring null cycles
to sampled parse trees and Inside-Outside expectation counts.
Informally, the essence of the algorithm is contained within the following two steps:
\begin{description}
\item[(i)] separating bifurcations
into those which have one or more empty children (and can therefore be
represented using transition or termination rules) and those that have
two nonempty children;
\item[(ii)] replacing all empty paths through null states with effective direct transitions between non-null states,
obtaining sum-over-paths probabilities by inverting the grammar's transition matrix.
\end{description}

Note that step (i) is unique to SCFGs; step (ii), in contrast, is very similar to the empty-path elimination algorithm for HMMs.




\subsubsection*{Dynamic programming algorithms for inference}

Once we have performed the transformations described above to remove
null cycles from the multiple-sequence SCFGs generated by our
model-construction algorithm, we can compute likelihoods and sample parse trees
using the standard CYK, Inside and Outside algorithms for multiple-sequence SCFGs \cite{Sankoff85,Durbin98}.

The asymptotic time and memory complexities of our inference algorithms
are essentially the same as for Sankoff's algorithm \cite{Sankoff85}:
the DP algorithms take memory $O(A \cdot L^{2N})$ and time $O(B \cdot L^{3N})$
for $N$ sequences of length $L$, where $A$ is the number of
(accessible) states in the multiple-SCFG and $B$ is the number of
bifurcations.
Note that $A$ and $B$ are also dependent on $N$ (see \secname{The TKFST model on a three-taxon phylogeny}).

Exact inference on a star phylogeny with $N$ extant sequences therefore
has complexities $O(A \cdot L^{2N})$ and $O(B \cdot L^{3N})$ in memory and
time (respectively) for a multiple-SCFG with $A$ states and $B$ bifurcations. As
described earlier, in practice we frequently have expert knowledge
(such as a curated multiple alignment)
about the structures and/or evolutionary histories of the sequences of
interest.  We can use this knowledge as a constraint to reduce the accessible volume, and hence the storage requirements, of the DP matrix \cite{Holmes2005}.
Algorithms \ref{alg:inside}--\ref{alg:cyktraceback}, described below, give the Inside, CYK,
Outside and CYK traceback algorithms for a three-taxon star phylogeny,
constrained using the ``fold envelope'' concept.

\paragraph{Fold Envelopes.}
We use the fold envelope concept \cite{HolmesRubin2002a,Holmes2004}
to constrain the set of structures which our algorithms consider.
A fold envelope $\foldenv^{(X)}$ for a sequence $X$ is a set of coordinate pairs satisfying
\beqn \eqnlabel{foldenv}
\foldenv^{(X)} \subseteq \left\{ (i,j):0 \le i \le j \le L^{(X)} \right\} \, ;
\quad L^{(X)} = |X| \, .
\eeqn
We consider a subsequence $x_{i+1} \dots x_{j}$ only if the corresponding coordinate pair $(i,j) \in \foldenv^{(X)}$.
The unconstrained fold envelope has set equality in \eqnref{foldenv}.

We use two orderings for sequences in the fold envelopes.  An inside-outside ordering is used for the iteration 
in the Inside algorithm: Subsequences are ordered such that each successive subsequence 
contains all previous subsequences in the fold envelope.  More precisely, subsequences in $\foldenv^{(X)}$ are sorted  
in the same order as coordinate pairs $(i,j)$ are generated by the
iteration $\{\,\mathrm{for}\, i = L^{(X)} \,\mathrm{to}\, 0 \,\,\{
\mathrm{for}\, j = i \,\mathrm{to}\, L^{(X)} \}\,\}$.

The Outside algorithm uses an outside-inside ordering, which is the exact reverse of the inside-outside ordering described above.
Subsequences in $\foldenv^{(X)}$ are sorted 
in the same order as coordinate pairs $(i,j)$ are generated by the 
iteration $\{\,\mathrm{for}\, i = 0 \,\mathrm{to}\, L^{(X)} \,\,\{ \mathrm{for}\, j = L^{(X)}\, \mathrm{to}\, i \}\,\}$.

We frequently refer to subsequences by their index in the fold envelope.
The $\mth$ subsequence in $\foldenv^{(X)}$ is labeled $m^{(X)}$ and corresponds to the coordinate pair $(i_{m}, j_{m})$.  The 
index of a pair $(i,j) \in \foldenv^{(X)}$ is $n^{(X)}[i,j]$.

In order to take full advantage of the reduction in computational complexity offered by restricting our inference algorithms to subsequences contained in the fold envelopes, we must avoid iterating over unreachable combinations of subsequences (unreachable because they are not permitted by the fold envelope constraints).
An efficient implementation relies on iterators over subsequences in the fold envelope which are connected by production rules of the ensemble grammar.
Inward and outward emission connections for a sequence $X$, specifying which subsequence is reachable from 
a given subsequence $m^{(X)}$ and ensemble state $\bvec{b}$, are defined as
\begin{align*}
c_{in}\left(\bvec{b}; m^{(X)}\right) &= n^{(X)} \left[ i_{m} + \Delta^{(X)}_L(\bvec{b}), j_{m} - \Delta^{(X)}_R(\bvec{b}) \right] \\
c_{out}\left(\bvec{b}; m^{(X)}\right) &= n^{(X)} \left[ i_{m} - \Delta^{(X)}_L(\bvec{b}), j_{m} + \Delta^{(X)}_R(\bvec{b}) \right] \, ,
\end{align*}
where the quantities $\Delta^{(X)}_L(\bvec{b})$ and $\Delta^{(X)}_R(\bvec{b})$ are the lengths of the left and right emissions of the ensemble state $\bvec{b}$ to the sequence $X$.
(Recall that the $\mth$ subsequence in $\foldenv^{(X)}$ is labeled $m^{(X)}$ and corresponds to the coordinate pair $(i_{m}, j_{m})$.)
The emission connection is undefined if the corresponding subsequence is not in the fold envelope.
Inward, outward-left and outward-right bifurcation connections, specifying which subsequences are connected by bifurcation production rules of the ensemble SCFG,
are defined for a subsequence $n^{(X)}$ as
\begin{align}
b_{in}(n^{(X)}) &= \left\{ \left( n^{(X)}_L,n^{(X)}_R \right): i_{n^{(X)}_L} = i_{n^{(X)}},\, j_{n^{(X)}_L} = i_{n^{(X)}_R},\, j_{n^{(X)}_R} = j_{n^{(X)}} \right\} \\
b_{out,L}(n^{(X)}) &= \left\{ \left( n^{(X)}_O,n^{(X)}_L \right): i_{n^{(X)}_L} = i_{n^{(X)}_O},\, j_{n^{(X)}_L} = i_{n^{(X)}},\, j_{n^{(X)}} = j_{n^{(X)}_O} \right\} \\
b_{out,R}(n^{(X)}) &= \left\{ \left( n^{(X)}_O,n^{(X)}_R \right): i_{n^{(X)}} = i_{n^{(X)}_O},\, j_{n^{(X)}} = i_{n^{(X)}_R},\, j_{n^{(X)}_R} = j_{n^{(X)}_O} \right\}
\end{align}
We generally write out explicit subsequence coordinate pairs $(i,j)$
when their usage will make mathematical formulas clearer and
fold-envelope labels $n^{(X)}$ when writing pseudocode.


\paragraph{The Inside algorithm.}
The Inside algorithm is used to calculate the likelihood of sequences under an ensemble model.  It is analogous to the Forward algorithm for HMMs.

The inside probability $\alpha_{\bvec{a}} \left(n^{(X)}, n^{(Y)}, n^{(Z)}\right)$ is the summed probability of the triplet of subsequences 
$\left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$ for sequences $X, Y, Z$
under all paths through the model which are rooted in state $\bvec{a}$.  
\algref{inside} gives pseudocode for the fold-envelope version of the Inside algorithm.  The subroutines 
$\mathrm{calcTransEmitProb}$, $\mathrm{calcLBifurcProb}$ and $\mathrm{calcRBifurcProb}$
used in the Inside algorithm are defined below.

The transition and emission probability $\mathrm{calcTransEmitProb}(\bvec{a}; \cdot)$ can be calculated 
by iterating over ensemble states $\bvec{b}$ which connect the subsequence triplet $\left(n^{(X)}, n^{(Y)}, n^{(Z)}\right)$ to others in the fold envelopes.
Pseudocode for the constrained calculation is given in \algref{insidetransemit}.

The left-bifurcation probability for an ensemble state $\bvec{a}$
bifurcating to two ensemble states,
\newline
$\mathrm{calcLBifurcProb}\left( \bvec{a}; n^{(X)}_L,n^{(X)}_R,n^{(Y)}_L,n^{(Y)}_R,n^{(Z)}_L,n^{(Z)}_R \right)$, is
\[ \sum_{\bvec{b}|\,\exists\, \bvec{a}\to\bvec{c}\bvec{b}} P (\bvec{a}\to\bvec{c}\,\bvec{b}) \, \alpha_{\bvec{c}}\left( n^{(X)}_L,n^{(Y)}_L,n^{(Z)}_L\right) \, \alpha_{\bvec{b}}\left( n^{(X)}_R,n^{(Y)}_R,n^{(Z)}_R\right) \]
and the right-bifurcation probability for an ensemble state $\bvec{a}$
bifurcating to two ensemble states,
\newline
$\mathrm{calcRBifurcProb}\left( \bvec{a}; n^{(X)}_L,n^{(X)}_R,n^{(Y)}_L,n^{(Y)}_R,n^{(Z)}_L,n^{(Z)}_R \right)$, is
\[ \sum_{\bvec{b}|\,\exists\, \bvec{a}\to\bvec{b}\bvec{d}} P (\bvec{a}\to\bvec{b}\,\bvec{d}) \, \alpha_{\bvec{b}}\left( n^{(X)}_L,n^{(Y)}_L,n^{(Z)}_L\right) \, \alpha_{\bvec{d}}\left( n^{(X)}_R,n^{(Y)}_R,n^{(Z)}_R\right) . \]
The boundary condition of the probability of 0-length subsequences is determined by the probability of transitions to $\Send$.
The termination condition is 
\[ P \left( X, Y, Z \right) = \alpha_{\Sstart}\left(N^{(X)}, N^{(Y)}, N^{(Z)}\right) \, , \]
where $\Sstart$ is the unique start state of the ensemble grammar and $N^{(X)}$ is the outermost subsequence for sequence $X$, etc.

Note that we are assuming that the transformations described in \secname{Exact elimination of null cycles in SCFGs} have been performed, such that there are no cycles of $\Snull$ states as well as no empty bifurcations.


\paragraph{The CYK algorithm.}
The CYK algorithm is used to calculate the probability of the
most-likely state path (or parse) capable of generating the input
sequences.  It is analogous to the Viterbi algorithm for HMMs.

The CYK algorithm can be obtained from the Inside algorithm by replacing sums over paths through the ensemble model
with the $\max$ operation.
The CYK probability for indices $\gamma_{\bvec{a}} \left(n^{(X)}, n^{(Y)}, n^{(Z)}\right)$ then represents
the probability of the most likely path through the model generating 
the triplet of subsequences $\left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$.

The resulting CYK algorithm is shown in \algref{cyk}.
The subroutine $\mathrm{calcTransEmitProb}$ is defined in \algref{cyktransemit}.  The subroutines $\mathrm{calcLBifurcProb}$ and $\mathrm{calcRBifurcProb}$
used in the CYK algorithm are defined as 
\[ \max_{\bvec{b}|\,\exists\, \bvec{a}\to\bvec{c}\bvec{b}} P (\bvec{a}\to\bvec{c}\,\bvec{b}) \, \gamma_{\bvec{c}}\left( n^{(X)}_L,n^{(Y)}_L,n^{(Z)}_L\right) \, \gamma_{\bvec{b}}\left( n^{(X)}_R,n^{(Y)}_R,n^{(Z)}_R\right) \]
and
\[ \max_{\bvec{b}|\,\exists\, \bvec{a}\to\bvec{b}\bvec{d}} P (\bvec{a}\to\bvec{b}\,\bvec{d}) \, \gamma_{\bvec{b}}\left( n^{(X)}_L,n^{(Y)}_L,n^{(Z)}_L\right) \, \alpha_{\bvec{d}}\left( n^{(X)}_R,n^{(Y)}_R,n^{(Z)}_R\right) . \]


\paragraph{The Outside algorithm.}
The Outside algorithm is primarily used an an intermediary for posterior decoding on the model.  It is analogous to the Backward algorithm for HMMs.

The outside probability $\beta_{\bvec{b}} \left( n^{(X)}, n^{(Y)}, n^{(Z)}\right)$ for an ensemble state $\bvec{b}$
is the summed probability of the sequences $X, Y, Z$
under all paths through the ensemble model which are rooted in the start state of the model, excluding all paths for the triplet of subsequences $\left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$
which are rooted in the ensemble state $\bvec{b}$.
\algref{outside} gives pseudocode for the fold-envelope version of the Outside algorithm.
The subroutines $\mathrm{calcTransEmitProb}$, $\mathrm{calcLBifurcProb}$ and $\mathrm{calcRBifurcProb}$
used in the Outside algorithm are defined below.

As with the Inside and CYK algorithms, the transition and emission probability $\mathrm{calcTransEmitProb}$ can be calculated efficiently using the subsequence connections defined earlier (\algref{outsidetransemit}).
The left-bifurcation probability $\mathrm{calcLBifurcProb}\left( \bvec{b}; n^{(X)}_O,n^{(X)}_L,n^{(Y)}_O,n^{(Y)}_L,n^{(Z)}_O,n^{(Z)}_L \right)$ is
\[ \sum_{\bvec{a}|\,\exists\, \bvec{a}\to\bvec{c}\bvec{b}} P (\bvec{a}\to\bvec{c}\,\bvec{b}) \, \beta_{\bvec{a}}\left( n^{(X)}_O,n^{(Y)}_O,n^{(Z)}_O\right) \, \alpha_{\bvec{c}}\left( n^{(X)}_L,n^{(Y)}_L,n^{(Z)}_L\right) \]
and the right-bifurcation probability $\mathrm{calcRBifurcProb}\left( \bvec{b}; n^{(X)}_O,n^{(X)}_R,n^{(Y)}_O,n^{(Y)}_R,n^{(Z)}_O,n^{(Z)}_R \right)$ is
\[ \sum_{\bvec{a}|\,\exists\, \bvec{a}\to\bvec{b}\bvec{d}} P (\bvec{a}\to\bvec{b}\,\bvec{d}) \, \beta_{\bvec{a}}\left( n^{(X)}_O,n^{(Y)}_O,n^{(Z)}_O\right) \, \alpha_{\bvec{d}}\left( n^{(X)}_R,n^{(Y)}_R,n^{(Z)}_R\right) \]
The boundary condition is just
\[
\beta_{\Sstart} \left(N^{(X)}, N^{(Y)}, N^{(Z)}\right) = 1\, ,
\]
where $N^{(X)}$ is the outermost subsequence for sequence $X$, etc.


\paragraph{The CYK traceback algorithm.}
The CYK traceback algorithm, in combination with the CYK algorithm, is
used to find the most-likely state path generating the extant sequences
(in other words, the maximum-likelihood parse generating the observed data).
It is analogous to the Viterbi traceback algorithm for HMMs.
\algref{cyktraceback} gives the constrained CYK traceback algorithm.








% Results and Discussion can be combined.
\newpage
\section*{Results}



\subsection*{Automated grammar construction}

We implemented our model construction algorithm on the three-taxon
star phylogeny.
Given a singlet transducer modeling ancestral structures and a branch
transducer modeling structural evolution, our Perl modules generate
C++ code for the corresponding jointly-normalized three-sequence
(Triplet) SCFG.
Any model of structural evolution which can be represented as a Pair
SCFG and factored into singlet and branch transducers is permitted as input to
the packages, allowing for flexible, automated model design.
The available software is described in \supptext{3}.

% Simultaneous alignment and folding of three RNA sequences is highly-demanding computationally.
% The completely-unconstrained algorithm requires time
% $O(L^{3N})$ and memory $O(L^{2N})$ and so, for $N \geq 3$, becomes very expensive.
% Even constrained versions are expensive:
% e.g., inferring the common ancestor of three RNA sequences {\em whose secondary structures have been experimentally determined}
% still takes at least $O(L^3)$ time and memory.

% Despite this expense, construction and analysis of the three-sequence model and algorithm is a useful step towards developing more practical inference algorithms.
% This point is illustrated by several papers in the molecular evolution literature,
% which describe algorithms for the practical reconstruction of indel histories in DNA and protein sequences
% \cite{HolmesBruno2001,JensenHein2002,RedelingsSuchard2005,PatenHolmesBirney2008}.
% In these papers, the generalization of a model from two sequences to three (or more)
% is followed by the observation that the resulting multiple-sequence problem is very expensive in memory;
% the memory complexity is then somehow reduced to the complexity of the two- or (in the case of \cite{JensenHein2002}) the three-sequence problem,
% with an accompanying tradeoff in time or accuracy.

% In particular, the work of Redelings and Suchard \cite{RedelingsSuchard2005}
% reduces a three-sequence inference problem
% into two Metropolis-Hastings steps (a {\em Propose} step and an {\em Accept} step),
% each of which reduces to a two-sequence inference problem.
% Thus, one expensive three-way alignment is decomposed into two less-expensive pairwise alignments.
% In the {\em Propose} step, two sequences are aligned and their common ancestor is sampled.
% In the {\em Accept} step, the proposed ancestor is aligned to the remaining sequence,
% and the move is accepted with a probability given by a Hastings ratio.

% The Redelings-Suchard approach is motivated by the fact that the
% two-sequence case is often tractable where the three-sequence case is not.
% This is especially true of the memory-intensive analsis of RNA secondary structure.
% While the three-sequence inference algorithms which we report here are computationally expensive,
% we believe that these results can be used to develop reduced-complexity algorithms
% (e.g., similar to those of Redelings and Suchard),
% allowing memory complexities similar to the pairwise case.
% The work described here may hopefully be regarded as one step towards the construction of such approaches
% (Metropolis-Hastings or otherwise).

\subsection*{A simple model of RNA structural evolution}

We illustrated our method for building models of structured sequences
using a model which was introduced in previous work,
the TKF Structure Tree \cite{Holmes2004}, a simplified probabilistic
model of the evolution of RNA structure.

The TKF Structure Tree (TKFST) model is based on the
Thorne-Kishino-Felsenstein (TKF) model of the stochastic evolution of
primary sequences via indel events \cite{ThorneEtal91}.  In the
original TKF model, sequence evolves under a time-homogeneous linear
birth-death-immigration process \cite{Kendall1948}.  Single characters (``links'')
are inserted with rate $\lambda$ and deleted with rate $\mu$.  At
equilibrium, sequences obey a geometric length distribution with
parameter $\kappa$.  Although this model has flaws (e.g., it lacks
affine gap penalties, rate heterogeneity and context-dependent
mutation rates), it illustrates many of the key ideas used by more
sophisticated indel models, notably the possibility for systematic
derivation of pairwise alignment automata from first principles via
analysis of birth-death processes \cite{Feller71,ThorneEtal91}.

The TKF Structure Tree model is an extension of the TKF model to RNA
structure.  In this model, loop and stem regions are
mutually nested (\figref{tkfst}):
the parameter $\pi_l(S)$ determines the proportion of links within loop sequences that are nested stems,
and every stem sequence has a nested loop at the end.
Single bases are inserted and deleted in loops with rates $\lambda_l$ and $\mu_l$;
similarly, base-pairs are inserted and deleted in stems with rates
$\lambda_s$ and $\mu_s$.
Both loops and stems have geometric length
distributions with parameters $\kappa_l = \lambda_l / \mu_l$ and $\kappa_s = \lambda_s / \mu_s$.  
Insertions of a new stem into an existing
loop sequence (or deletions of an existing stem) occur at the same
rate as single-base insertions (or deletions) and can model
large-scale structural changes (\figref{tkfst-mutations}).

We parametrized the singlet and branch transducers of the TKFST model
using estimates reported by a phylo-grammar for RNA secondary
structure prediction, \pfold\ \cite{KnudsenHein2003}, and an
implementation of pairwise alignment for the TKF Structure Tree model,
\evoldoer\ \cite{Holmes2004}.
The equilibrium distributions of unpaired and paired nucleotides of
the singlet and branch transducers, as well as the substitution models
of unpaired and paired nucleotides of the branch transducers, were
derived from the substitution rate matrices of the \pfold\ program.
These rate matrices, which have proven useful for RNA structure
prediction \cite{KnudsenHein2003,DowellEddy2004,BradleyEtAl2008},
were derived from the Bayreuth tRNA database \cite{SprinzlEtAl1998}
and the European large subunit rRNA database \cite{DeRijkEtAl1998}.

This continuous-time model corresponds to a Pair SCFG and as such
fits neatly into our modeling framework once the probability
distribution is appropriately factored into marginal and conditional
distributions (generated by singlet and branch transducers).
Tables \ref{tab:tkfstsinglet-types} and \ref{tab:tkfstsinglet} show the states 
and transitions of the singlet transducer (single-sequence SCFG) 
which generates ancestral sequence under the Structure Tree model.
Tables \ref{tab:tkfstbranch-types} and \ref{tab:tkfstbranch} show the states
and transitions of the branch transducer (conditionally-normalized Pair SCFG)
which evolves a sequence and structure along a branch of the phylogenetic tree.

The equilibrium distribution and transition probabilities between states of the TKFST model can be 
expressed in terms of functions of the evolutionary time along a branch
and the insertion and deletion rates $\lambda_l$ and $\mu_l$ of the model.
The length of ancestral sequences is geometric in $\kappa_l$ (\tabref{tkfstsinglet}), defined as $\kappa_l = \lambda_l / \mu_l$.
The three functions $\alpha(t)$, $\beta(t)$ and $\gamma(t)$ which govern 
the transition probabilities in \tabref{tkfstbranch} are defined
for loop sequences as
\begin{align}
  \alpha_l (t) &= \exp \left( -\mu_l t \right) \nonumber \\
  \beta_l (t) &= \frac{\lambda_l \left( 1 - \exp \left((\lambda_l - \mu_l) t \right) \right)}{\mu_l - \lambda_l \exp \left( (\lambda_l - \mu_l) t \right) } \nonumber \\
  \gamma_l (t) &= 1 - \frac{\mu_l \left( 1 - \exp \left((\lambda_l - \mu_l) t \right) \right)}{\left( 1 - \exp (- \mu_l t) \right) \left(\mu_l - \lambda_l \exp \left( (\lambda_l - \mu_l) t \right) \right) } \nonumber
\end{align}
and similarly for stem sequences \cite{Holmes2004}.

A few other useful statistics for the TKFST model:
the expected number of links in a loop sequence is $K_l = \frac{\lambda_l}{\mu_l - \lambda_l}$
and in a stem sequence $K_s = \frac{\lambda_s}{\mu_s - \lambda_s}$.
Since $\pi_l(S)$ of the links in a loop sequence are nested stems,
and since each stem has twice as many nucleotides as it has links (since each link is a base {\em pair}),
the expected number of bases in a loop sequence is
\[
B_l = \frac{K_l (1-\pi_l(S)) + 2K_l \pi_l(S)} {1 - \pi_l(S) K_l}
\]
The expected number of bases in a stem sequence is
\[
B_s = 2K_s + B_l
\]
The expected number of bases that are created/removed when a loop-sequence link is inserted/deleted is
\[
D_l = (1-\pi_l(S)) + \pi_l(S) B_s
\]
The expected number of stems directly rooted in a given loop sequence is
$U = \pi_l(S) K_l$
and the expected number of stems directly rooted in, {\bf or indirectly descended from}, a given loop sequence is
$V = U / (1 - U)$
(note that this is also the expected total number of loop sequences indirectly descended from a given loop sequence).
Therefore, in the equilibrium structure,
the expected number of stems is $V$;
of loops, $V+1$;
of unpaired bases, $K_l (1 - \pi_l(S)) (V+1)$;
and of base-pairs, $K_s V$.
In a tree with total branch length $T$,
the expected number of single-base deletions is $\mu_l T K_l (1 - \pi_l(S)) (V+1)$;
of base-pair deletions, $\mu_s T K_s V$;
and of substructure deletions, $\mu_l T V$.


\subsection*{Assessing TKFST as a model of RNA structure}

The TKFST model, like the original TKF model, probably needs
refinements in order to accurately model many structural RNAs.  For
example, it fails to model certain phenomena observed in natural
RNA structures (such as base-stacking or tetraloops) and in alignments
of those structures (such as helix slippage).
We assessed its appropriateness as a model of RNA structural evolution
by conducting benchmarks of its capabilities for (1) multiple sequence
alignment of structured RNAs, summing over all possible structures,
and (2) structure prediction of homologous structured RNAs and
comparing its performance to \stemloc\ (one of the better-performing pairwise
SCFGs used for RNA multiple alignment \cite{BradleyPachterHolmes2008}).  The
results of these benchmarks, reported in \tabref{bralibaseII-align}
and \tabref{bralibaseII-struct}, suggest that TKFST is a
useful guide for deriving more complicated models of RNA evolution:
while it has relatively poor sensitivity (but high positive predictive
value) as a base-pairing predictor, it is competitive with one of the
most accurate RNA multiple sequence alignment programs \cite{BradleyPachterHolmes2008}.

TKFST's poorer performance at base-pairing prediction is likely
due to its much-simpler model of RNA structure.
The richer grammar, as described in \cite{Holmes2005},
is much more complex than TKFST:
excluding the substitution model, it has 14 free parameters
(compared to TKFST's 4),
uses an affine gap penalty
(compared to TKFST's linear gap penalty),
and explicitly models structural features
such as multiple-branched loops, symmetric/asymmetric bulges, and minimum loop lengths.
Unlike TKFST, the richer grammar is structurally unambiguous:
a one-to-one mapping exists from structures to parse trees.
Although we use the TKFST model as an illustrative example of a Pair
SCFG that can be extended with our method, the model is not
fundamental to our approach and can be replaced by a different
and more realistic pairwise model, such as the \stemloc\ pairwise SCFG used in 
these comparisons \cite{BradleyPachterHolmes2008}.
We anticipate that further improvements should be possible by reviewing
other comparisons of SCFGs at structure prediction,
such as the study of \cite{DowellEddy2004}.


\subsection*{The TKFST model on a three-taxon phylogeny}

We used our model-construction algorithm to build the grammar
corresponding to the TKFST model acting on a star phylogeny with three
(extant) leaf sequences and a single (unobserved) ancestral
sequence. We chose this phylogeny for two reasons: (1) it is the
simplest extension of the well-studied, standard two-sequence (Pair
SCFG) model and (2) algorithms on a phylogeny with three leaves
should be sufficient for ergodic sampling of reconstructions on any larger phylogeny,
using, e.g., a Gibbs-sampling MCMC kernel \cite{JensenHein2002}
or a progressive suboptimal-alignment sampling heuristic \cite{PatenHolmesBirney2008}.

The statistics of the TKFST model on the three-taxon phylogeny
illustrate the advantages of our procedure for model construction.
While the singlet and branch transducers are relatively simple---the
singlet transducer, shown in \tabref{tkfstsinglet}, has 7 total states
and 2 bifurcation states and the branch transducer, shown in
\tabref{tkfstbranch}, has 21 total states and 6 bifurcation
states---the ensemble model of three extant sequences is very complex.
The naive exponential upper-bound gives a maximal state space of size
$O(7 \cdot 21^{3}) \Rightarrow 6 \cdot 10^4$ states.  Using our
uninformed search algorithm, we determined that there are 287
accessible states and 686 possible transitions between these states
(compare with the $287^2 \simeq 8 \cdot 10^4$ transitions estimated
with the exponential calculation).  After performing the
transformations described in \secname{Exact elimination of null cycles in SCFGs} to
eliminate useless windback states, the ensemble model has a reduced
state space with 230 states, albeit at the cost of extra transitions,
bring the total to 1,789 transitions (here we are trading reduced
memory complexity, which is linear in the number of states, for
increased time complexity, which is linear in the number of
transitions).  Note that both before and after the reduction in
complexity, the total number of states and transitions are less than
the approximate bounds of $O(a \cdot b \cdot N) = O(7 \cdot 21 \cdot
3) \Rightarrow 441$ states and $O(a \cdot b^2 \cdot N) = O(7 \cdot
21^2 \cdot 3) \Rightarrow 9,261$ transitions suggested in \secname{The composition algorithm.}
 Nonetheless, the extreme complexity of the
ensemble model, despite the simplicity of the underlying model of RNA
structure, makes clear the necessity for automated procedures for
model construction.  Dataset S1 gives the state space of the ensemble
model constructed by the search algorithm and Dataset S2 the reduced
model after eliminating windback states; both are in Graphviz format for
visualization and show the state of the singlet transducer generating
ancestral sequence as well as the states of the branch transducers
generating observed sequences.

We implemented constrained maximum-likelihood inference of the structural alignment 
and ancestral structure of three extant sequences in a C++ program (\indiegram).
For tractability, \indiegram\ uses the concept of fold envelopes
described earlier to limit the fold space considered by the CYK algorithm,
permitting structural information for the three extant sequences to be
(optionally) supplied as input.
If no structural information is supplied, then \indiegram\
uses a single-sequence SCFG to estimate a set of plausible folds \cite{Holmes2005},
which are used to constrain the CYK algorithm.

The inference algorithms in \indiegram\ could be further constrained
to enforce, for example, a fixed multiple alignment or a consensus
structure for extant sequences.  While experimentally-determined
structures of individual RNAs are relatively rare, curated deep sequence
alignments, such as those constructed for ribosomal RNAs
\cite{Gutell93}, are frequently available for characterized RNA families.  By constraining the
inference algorithms with such sequence alignments, the memory and
time complexity of the algorithms could be dramatically reduced.  Such
constraints can be naturally expressed with ``alignment envelopes,''
the alignment-space analogue of fold envelopes \cite{Holmes2005}.
However, in this paper we focus on model construction and inference
algorithms and postpone exploration of heuristics and constraints of
these algorithms for future work.


\subsection*{Reconstructing small RNAs with the TKFST model}

While reconstructing large RNAs such as ribosomal subunits is
currently computationally-inaccessible without further heuristics to
constrain our algorithms, reconstructing small RNAs of biological
interest will soon be feasible.
\tabref{complexities} shows estimates of the memory and time required
to reconstruct biologically-interesting subunits of 
the \emph{nanos} 3' translational control element and tRNAs,
as well as two small RNAs which show significant structural
divergence, the Y RNAs and Group II introns, and therefore promise to be
interesting candidates for ancestral reconstruction.
The reconstructed structures for three \emph{nanos} 3'
translational control elements (TCEs) and three tRNAs, which could be
analyzed given current computational limitations, can be found at
\indiegramurl; however, the phylogenetic trees relating the tested
sequences have short branch lengths, making the reconstruction problem easy by forcing the reconstructed structures to
be essentially-identical to those of one of the extant RNAs.


\subsection*{Comparison of alignment methods}

Guided by our experience with the \emph{nanos} 3' TCE and tRNA, where
the reconstruction problem was made easy by the presence of a close
outgroup, we conducted a simulation study of the dependence of reconstruction accuracy on outgroup branch length,
with the further goal of comparing the performance of our reconstruction method (when simulating directly from the model)
to simpler reconstruction methods that ignore either structure or phylogeny.
(We here use the term ``outgroup'' loosely to denote the
variable-length branch in our three-taxon study,
where the other two branches are held at unit length.)


We simulated the evolution of RNAs under the TKFST model along
three-taxon phylogenies (with one internal node), where we kept the branch lengths of two
sibling species constant and varied the branch length of the
outgroup between $[0, 2.5]$ at steps of size $0.1$.
    Parameters used in the simulation were $\lambda_l = 0.025$ and $\mu_l = 0.03$ for
    loop sequence and $\lambda_l = 0.007$ and $\mu_l = 0.01$ for stem
    sequence; the probability of a stem insertion was $0.1$.  These
    yielded a mean loop length of 5 bp and a mean stem length of 2.33 bp,
    with $\sim 0.3$ substructure indels per alignment.
    We selected alignments to reconstruct by requiring
    that there be at least two ancestral stems, loops of length $\in [3,
    10]$ bp and stems of length $\in [1, 20]$ bp; to reduce the complexity of
    our algorithms we additionally required that the sequences have
    lengths $\in [30, 70]$ bp.

We then attempted three-way multiple alignment (and, in some cases, reconstruction of the ancestor)
using a variety of statistical inference algorithms.
We sought insight as to the relative importance of the following factors in reconstructing ancestral RNA:
(i) modeling the secondary structure;
(ii) modeling the phylogenetic topology \& branch lengths;
(iii) using posterior-decoding algorithms to maximize the expected alignment {\em accuracy},
rather than picking the single {\em most likely} alignment \cite{Holmes98,SchwartzPachter2007,BradleyPachterHolmes2008}.

The alignment programs we used in this benchmark were
\indiegram\ (exact ML inference of alignment and ancestral structure, given phylogeny, descendant structures and correct model);
\stemloc\ (a greedy ML heuristic, ignoring phylogeny in favor of a single-linkage clustering of the descendant structures);
\stemlocama\ (a posterior-decoding heuristic, maximizing the alignment's {\em expected accuracy} rather than its {\em likelihood});
and
\handel\ (ML alignment under various indel models that ignore secondary structure completely).
In detail, the reconstruction methods were

\begin{description}
\item{\stemloc:} the \stemloc\ program was used to align the three sequences via single-linkage clustering with a Pair SCFG \cite{Holmes2005}.
The structures of the leaf sequences were provided, but not the phylogenetic branch lengths.
{\bf This model improves on the previous model (Long Indel) by introducing RNA secondary structure, though it no longer models phylogeny as rigorously as the Long Indel model} (it uses single-linkage clustering instead of a true phylogeny).
\item{\stemlocama:} the \stemloc\ program was used to align the three sequences in ``sequence annealing'' mode,
 a posterior decoding method that attempts to optimize AMA, a sum-over-pairs alignment accuracy metric \cite{BradleyPachterHolmes2008}.
The structures of the leaf sequences were provided, but not the phylogenetic branch lengths.
{\bf This program uses the previous model but instead of maximizing likelihood, it attempts to maximize an alignment accuracy metric.}
\item{TKF91:} with the TKF91 model \cite{ThorneEtal91}, the \handel\ package \cite{HolmesBruno2001,Holmes2003,Holmes2007} was used to align the three extant sequences and reconstruct the ancestor.
The correct phylogenetic tree and branch lengths were supplied (as they were for the \indiegram\ benchmark).
The insertion, deletion and substitution rates for the TKF91 model were set equal to those of the loop submodel of TKFST.
{\bf This may be understood as a naive reconstruction that completely ignores the stem sub-model of TKFST.}
\item{Long Indel:} with a single-event trajectory approximation to the long indel model \cite{MiklosLunterHolmes2004}, the \handel\ package was used to align the three extant sequences and reconstruct the ancestor.
The correct phylogenetic tree and branch lengths were supplied.
The deletion and substitution rates were set equal to those of the loop submodel of TKFST.
The mean indel length was set equal to $D_l$, the mean number of bases that are created/removed by an insertion/deletion in the loop submodel of TKFST;
the mean equilibrium sequence length (and thereby the insertion rate) was equal to $B_l$, the mean number of bases in TKFST at equilibrium
(\secname{A simple model of RNA structural evolution} has formulae for these quantities in terms of the TKFST rate parameters).
{\bf This model improves on the previous model (TKF91) by introducing affine gap penalties.}
\end{description}

We focused primarily on alignment accuracy, under the simplifying assumption that this will be a good indicator for
(and perhaps the primary determinant of) the accuracy of ancestral reconstruction.

We first consider the {\em perfect alignment rate}; that is, the number of times each method gets the alignment exactly correct.
Theory predicts that ML inference, using the correct model and parameters, should maximize the perfect alignment rate.
Inspecting \figref{perfect}, we find this to be the case, except when the outgroup is very distant
and the best perfect alignment rate drops below 0.05 (at which point 125 trials may not be sampling it sufficiently).
We also note that the ML version of \stemloc\ is near-optimal, and slightly better than the posterior-decoding \stemloc-AMA.
Finally, we note that the structure-blind models (TKF91 and Long Indel) perform consistently worse than the structure-aware methods,
with no decisive advantage shown by either TKF91 (linear gap penalty) or Long Indel (affine gap penalty).

A subtly different trend is apparent when we look at the accuracy of the returned alignment,
measured not by the all-or-nothing metric of whether the alignment is {\em perfect},
but rather by a metric that count the number of correct alignment columns.
\figref{ama} shows the {\em Alignment Metric Accuracy} (AMA),
a generalization of the {\em Sum-of Pairs Score} (SPS)
which measures the proportion of residues which are correctly aligned, averaged over all pairs of sequences \cite{SchwartzMyersPachter2006}.
Here, we see that \stemlocama---which attempts to find the alignment with maximum expected AMA---edges out both
\indiegram\ and the ML version of \stemloc.
The decision-theoretic scoring scheme of \stemlocama\ appears to offset the minor incorrectness of its model.

Again, when looking at the AMA statistics, the most important factor is clearly the incorporation of some form of basepair structure
into the model: \handel, whether using TKF91 or the Long Indel model, performs much worse than the SCFG-based methods.
This is to be expected: whenever a basepair-aware method aligns one half of a basepair, it gets the other nucleotide
correctly aligned for free.



\section*{Discussion}


Following the conception of paleogenetics \cite{PaulingZuckerkandl63},
a large number of synthetic reconstructions of ancestral protein sequences have been
reported in the literature
\cite{MalcolmEtAl90,StackhouseEtAl90,ZhangRosenberg2002,GaucherEtAl2003,ThomsonEtAl2005,ChangEtAl2002,SunEtAl2002,OrtlundEtAl2007}.
There is also scientific interest in reconstructing DNA sequences
\cite{IvicsEtAl91,AdeyEtAl94,BlanchetteEtAl2004,NoonanEtAl2006,Gaucher2007b,EliasTuller2007,PatenHolmesBirney2008}.
Given the importance of the RNA world hypothesis to
current discussions of the origin of life \cite{MarintchevWagner2004,Muller2005,CavalierSmith2006,WilliamKoonin2006,Forterre2006,Yakhnin2007,DanchinEtAl2007},
the many modern-day relics of this world
 \cite{LeeEtAl93,LoweEddy99,Eddy01,MandalEtAl2003}
and the recent proposal of a structural model for the primordial ribosome
 \cite{SmithEtAl2008},
we believe that phylogenetic reconstruction of ancient RNA is a significant
problem, deserving of strong bioinformatics support.


% Prior art
The work reported in this paper builds on extensive prior art in the areas of evolutionary modeling and ancestral reconstruction.
Reviewing all of this would take several books, but we can note some key references.
The reconstruction of ancient sequences was first proposed in 1963 by Pauling and Zuckerkandl \cite{PaulingZuckerkandl63};
current applications of this idea, mostly using substitution models, are surveyed in the book edited by Liberles \cite{Liberles2007}.
Many algorithms in phylogenetics implicitly reconstruct substitution histories,
whether by parsimony \cite{Edwards63,HendyPenny82} or likelihood \cite{Felsenstein81}.
There is a substantial body of work to model indels on phylogenies
\cite{ThorneEtal91,HeinEtal2000,Hein2001,HolmesBruno2001,SteelHein2001,Holmes2003,KnudsenMiyamoto2003,LunterSongMiklosHein2003,MiklosLunterHolmes2004,LunterEtAl2004,BradleyHolmes2007,SatijaEtAl2008}.
Recent work has extended these ideas to the reconstruction of indel
histories \cite{KimSinha2007,DialloEtAl2007},
particularly at the genomic scale \cite{MillerHausslerEtAl2006,PatenHolmesBirney2008}.
There is also prior work in computational linguistics
on the theory of transducers for sequences \cite{MohriPereiraRiley2000}
and parse trees \cite{Rounds70,Thatcher70,GecsegSteinby97,ComonEtAl2007-TreeTransducers}
(from which we take the terms ``string transducer'' and ``parse-tree transducer'').
We draw on the bioinformatics literature for SCFGs
\cite{Eddy94,Sakakibara94c,Durbin98},
especially Pair SCFGs \cite{RivasEddy99,Holmes2005,DowellEddy2006}
and phylogenetic SCFGs \cite{KnudsenHein2003}.
In particular, an early example of a pairwise conditional model $P(Y|X)$ for structure-dependent RNA evolution
was given by Eddy {\em et al} \cite{KleinEddy2003}.
A conditional framework similar to ours in some respects is described
by Sakakibara {\em et al} \cite{Sakakibara2003}.
The dynamic programming inference algorithms for multiple-sequence SCFGs are closely related to the protosequence algorithm of Sankoff \cite{Sankoff85}.
%a seminal work in both RNA structural alignment and ancestral reconstruction.

% In this paper we have reported innovations to two programs, \xrate\ and \stemloc,
% rendering them suitable for the challenge of reconstructing
% the ancestral RNA world from its modern descendants.
% The \xrate\ program can now reconstruct ancestral RNA substitution histories,
% while \stemloc\ can align and predict RNA structures
% using externally-supplied grammars
% (including grammars derived from evolutionary models).
% We have tested these programs using simulations, cross-validations, alignment benchmarks and structure prediction benchmarks.

% Building on these results, we have presented
% a general algorithm for constructing a multiple-sequence stochastic grammar
% modeling the common phylogenetic descent of a group of RNA sequences,
% along with a specific implementation of this algorithm---\indiegram---suitable
% for three-way RNA alignment and reconstruction.
% Using the TKF Structure Tree model, we demonstrated
% the capability of such composite grammars
% to infer ancestral structures of structured RNAs.

While we have focused on the TKF Structure Tree model in our Results,
our model-construction algorithm is applicable to any model of the evolution of secondary
structure which can be expressed as a Pair SCFG.
Realistic structural and thermodynamic effects---such as base-stacking
or loop length distributions---can, in principle, be incorporated.
%Furthermore, while an evolutionary model of structural evolution
%is necessarily complex,
%our model-construction algorithm enforces a compact parametrization,
%allowing fast training on structural alignments of pairs of sequences.
Other phenomena of RNA evolution may prove more difficult:
modeling helix slippage with a branch transducer is awkward,
let alone more radical changes in structure;
pseudoknots, too, are impossible with the models we have described here.
Even so, variants of our models could be used for proposing candidate alignments
for more accurate scoring by such models.

An implementation of inference algorithms for models on the three-taxon phylogeny
is sufficient to construct a MCMC sampling algorithm
over many sequences on an arbitrary phylogeny.
A sketch of such a sampling algorithm is as follows:
at each step of the sampling algorithm, we re-sample the sequence
and structure of the ancestral node $W$,
conditioned on the sequences and structures of $X$, $Y$ and $Z$.
The structural alignment of all four sequences can change at each step,
providing for fast mixing and guaranteeing ergodicity.
This move is similar to the sampler proposed by \cite{JensenHein2002} for 
models with a HMM structure.
Note that this, in principle, permits construction of a crude sampler
to simultaneously infer phylogeny as well, by proposing and accepting
or rejecting changes to the underlying tree as well as the implied
structural alignment.


% With reference to the motivating problem of reconstructing ribosomal RNA,
% the sequence-level reconstructions with \xrate\ 
% (described in \secref{subst-reconstruction})
% are certainly feasible on computing resources available now or in the near future.

Reconstructing structural changes of large RNAs
using the three-way sampling kernel which we have described
would require resources far in excess of those currently available;
barring the availability of supercomputers with terabytes of memory,
such algorithms will only be feasible for short RNAs (\tabref{complexities}).
A promising direction is to consider variations on the three-way sampling kernel,
such as the importance-sampling approach described for the TKF model
by \cite{RedelingsSuchard2005}.
This approach first proposes an ancestor $W$ by aligning extant
sequence $X$ to $Y$ (ignoring $Z$); then, in a second step, the proposed $W$ is
independently aligned to $Z$. The proposed three-way alignment and
reconstruction is then randomly accepted (or rejected) using a
Hastings ratio based on the three-way transducer composition. The
complexity of this kernel is the same as the pairwise case;
with suitable constraints, this is feasible for RNA
grammars on present hardware, at least for ribosomal domains (if not
yet whole subunits---although pairwise alignment of those should also
be possible soon). The approach of Redelings and Suchard therefore
merits future consideration in the context of modeling the evolution
of RNAs on a tree.

An alternative MCMC scheme for sampling RNA phylogeny, structure and
alignment was developed for the SimulFold program
\cite{MeyerMiklos2007}.  SimulFold does not use a strictly normalized
probabilistic model, resulting in some oddities in the ways that
structure and indels interact (for example, it does not penalize
deletion of one half of a basepair).  Currently, it is not clear how
appropriate SimulFold would be for ancestral reconstruction, although
it has several advantages (e.g., explicit treatment of pseudoknots).
Of course, MCMC kernels are inherently adaptable to other purposes:
the MCMC moves developed for SimulFold may be useful for inference
under different models.

This paper focuses on the case where the tree topology is known, but
many of the methods which we have described can be extended to the
more general case where none of the possible constraints (phylogeny,
structure or alignment) are final.  For example, the probabilistic
framework readily allows us to compare likelihoods of two different
phylogenetic trees by constructing a composite transducer for each
tree.  Thus, the MCMC samplers described above for alignments could,
in principal, be extended to phylogenies (albeit at a computational
cost).

While MCMC provides the most information about the posterior distribution of evolutionary histories,
in practice a maximum likelihood inference may be adequate (and typically much faster).
The progressive profiling used by the \ortheus\ program for
reconstructing ancestral genomes is promising \cite{PatenHolmesBirney2008}.
This approach is similar to a progressive multiple alignment algorithm, in that it proceeds via a single postorder (leaf-to-root) traversal of the phylogeny.
As each node is visited, a profile is generated for that node, by aligning the profiles of its children to a composite transducer using DP, then sampling a finite number of traceback paths through the DP matrix.
The profile is not linear: the sampled paths instead form a reticulate network, a.k.a. a partial order graph \cite{LeeGrassoSharlow2002}.
An equivalent of \ortheus\ for RNA reconstruction should be possible,
representing the intermediate profiles using transducers.

Given the excellent performance of \stemlocama's sequence annealing, particularly when measured using its own scoring metric (AMA),
such posterior-decoding methods should also be considered for reconstruction.

In summary, the evolutionary models and algorithms we have described form a
systematic theoretical platform on which we can test different optimization and sampling strategies
for studying the structural evolution of RNA gene families in detail.
Stochastic grammars are powerful tools for this task, although they will not be the only tools we need,
particularly as we move towards modeling RNA evolution in greater detail.
Our hope is that these algorithms will allow us to test and refine our
understanding of RNA evolution by computational reconstruction and (eventually)
direct experimental investigation of early ribonucleic machines.

%All programs described here are released under the GNU General Public License and
%can be download from \darturl\ as part of the \dart\ software package for sequence analysis.










% Do NOT remove this, even if you are not including acknowledgments
\newpage
\section*{Acknowledgments}

We thank
Jeff Thorne,
Jamie Cate,
Jennifer Doudna,
Jotun Hein,
David Haussler,
Sean Eddy,
Elena Rivas and
Eric Westhof
for inspirational discussions.
We are grateful to Ben Redelings and one anonymous referee for illuminating criticism.


%\section*{References}
% The bibtex filename
\bibliography{../latex-inputs/alignment,../latex-inputs/reconstruction,../latex-inputs/duplication,../latex-inputs/genomics,../latex-inputs/ncrna,../latex-inputs/url}

\clearpage
\section*{Figure Legends}

\begin{figure}[!ht]
  \centering
%  \includegraphics [scale=0.4] {figs/parent.pdf}
   \caption{
     \textbf{A simple example of transducer composition to build an
       evolutionary model of two extant sequences.}
    An ancestral sequence $W$ evolves into two descendant sequences $X$ and $Y$.
     A singlet transducer (the horizontal gray box) emits an ancestral sequence and structure
     and two branch transducers (the gray boxes labeled $T_X$ and $T_Y$)
     mutate it according to the specified evolutionary model.
     Gray nodes correspond to observed data and white nodes unobserved data.
   }
   \figlabel{parent}
 \end{figure}
 
 \begin{figure}[!ht]
   \centering
 %  \includegraphics [scale=0.4] {figs/threeway.pdf}
   \caption{
     \textbf{Transducer composition on a star phylogeny with three
       (extant) leaf sequences.}
     An ancestral sequence $W$ evolves into three descendant sequences $X$, $Y$ and $Z$.
     A singlet transducer (the horizontal gray box) emits an ancestral sequence and structure
     and three branch transducers (the gray boxes labeled $T_X$, $T_Y$ and $T_Z$)
     mutate it according to the specified evolutionary model.
     Gray nodes correspond to observed data and white nodes unobserved data.
     If the branch transducers are time-reversible, then this star phylogeny with three leaves is
     the neighborhood of any interior node in a (binary) phylogenetic tree, 
     from which it follows that evaluating the likelihood function
     on this star phylogeny is sufficient, in principle, for a sampling algorithm on an arbitrary phylogeny.
   }
\figlabel{threeway}
 \end{figure}
 
\begin{figure}[!ht]
  \centering
%  \includegraphics [width=0.5\textwidth] {figs_plos/stree-with-structure.pdf}
  \caption{
    \textbf{The TKF Structure Tree model represents the
      evolution of RNA structure as nested stem and loop sequences.}
    The model consists of recursively nested loop sequences (gray,
    horizontal) and stem sequences (black, vertical). The loops are
    sequences of unpaired bases and the stems are sequences of
    covarying base-pairs. Both loop and stem sequences evolve
    according to the Thorne-Kishino-Felsenstein (TKF) model
    \cite{ThorneEtal91} of molecular evolution.  Figure is extended
    from a similar version in \cite{Holmes2004}.
  }
  \figlabel{tkfst}
\end{figure}

\begin{figure}[!ht]
  \centering
%  \includegraphics [width=0.5\textwidth] {figs_plos/stree-mutations-with-structures.pdf}
  \caption{
    \textbf{Evolution of a RNA structure under the TKF Structure Tree
      model.}
    The TKF Structure Tree model includes phenomena such as point
    mutations in loop sequences ($1 \rightarrow 2$ and $4 \rightarrow 5$), covariant
    mutations in stem sequences ($2 \rightarrow 3$), insertions in
    loop sequences ($3 \rightarrow 4$), insertions in stem sequences
    ($5 \rightarrow 6$), structural insertions ($6 \rightarrow 7$),
    and structural deletions ($7 \rightarrow 8$).
   Figure is extended from a similar version in \cite{Holmes2004}.
  }
  \figlabel{tkfst-mutations}
\end{figure}

% figure produced automatically with simulations/plots.r from simulations/inferred/indiegram.analysis
\begin{figure}[!ht]
  \centering
  % \includegraphics[width=5in]{figs_plos/perfect.pdf}
  \caption{
    \textbf{Dependence of perfect alignment rate on outgroup branch
      length.}
    We investigated the perfect alignment rate
    (the number of times that a given alignment program estimates the alignment 100\% correctly, with no errors)
    as a function of outgroup branch length, simulating the
    evolution of three structural RNAs under our model.  The two
    sister species were equidistant from the ancestral sequence, with
    a branch length of 1, corresponding to one expected
    substitution per site in loop sequence.  We allowed the outgroup
    branch length $t$ to vary between $[0, 2.5]$.  We selected 25 equally spaced values of $t$ in this range, spaced $0.1$ apart,
    and simulated 25 alignments for each value of $t$, using TKFST model parameters described in the text.
    Since the perfect alignment rate is rather low, we further aggregated the $t$-values for this plot into bins of five;
    thus, for example, the bin named ``$0 to 0.5$'' includes $t \in \{ 0, 0.1, 0.2, 0.3, 0.4 \}$.
    The vertical axis counts the number of perfect alignments in each bin, out of a total of 125 trials per bin.
}
  \figlabel{perfect}
\end{figure}

% figure produced automatically with simulations/plots.r from simulations/inferred/indiegram.analysis
\begin{figure}[!ht]
  \centering
  % \includegraphics[width=5in]{figs_plos/ama.pdf}
  \caption{
    \textbf{Dependence of reconstruction accuracy on outgroup branch
      length.}
    We investigated the dependence of structural reconstruction and
    alignment accuracy on outgroup branch length by simulating the
    evolution of three structural RNAs under our model.  The two
    sister species were equidistant from the ancestral sequence, with
    a branch length of 1, corresponding to one expected
    substitution per site in loop sequence.  We allowed the outgroup
    branch length $t$ to vary between $[0, 2.5]$.  We selected 25 equally spaced values of $t$ in this range, spaced $0.1$ apart,
    and simulated 25 alignments for each value of $t$, using TKFST model parameters described in the text.
    The Alignment Metric Accuracy (AMA) is, roughly, the proportion of residues that are correctly
    aligned, averaged over all pairs of sequences
    (see \cite{SchwartzMyersPachter2006} for a precise definition; we used AMA with Gap Factor 1).
}
  \figlabel{ama}
\end{figure}


\clearpage
\section*{Tables}

\begin{table}[!ht]
  \caption{
    \textbf{State types of the singlet transducer (single-sequence
      SCFG) of the TKF Structure Tree model.}}
  \begin{tabular}{|l|rrrl|}
    \hline
    State & $\type$ & $\absorb$ & $\emit$ & description \\ \hline
    $L$ & $\Sstart$ & & & Start of a loop \\ \hline
    $I_L$ & $\Sinsert$ & & $(x,\Tnull)$ & Single-base emission \\ \hline \hline
    $S$ & $\Sstart$ & & & Start of a stem \\ \hline
    $I_S$ & $\Sinsert$ & & $(x,y)$ & Base-pair emission \\ \hline \hline
    $B$ & $\Sinsert$ & & $(L\,S)$ & Bifurcation \\ \hline
  \end{tabular}
  \begin{flushleft}
    Singlet transducers can only have states of type $\Sstart$ or
    $\Sinsert$.
  \end{flushleft}
 \tablabel{tkfstsinglet-types}
\end{table}


% Use table to allow the table to span the width of the entire page.
\begin{table}[!ht]
  \caption{
    \textbf{Singlet transducer (single-sequence SCFG) of the TKF Structure Tree model.}}
  \begin{tabular}{|rcl|r||rcl|r|}
    \hline
    Source & $\rightarrow$ & Destination & probability & Source & $\rightarrow$ & Destination & probability \\ \hline
    $L$ & $\rightarrow$ & $u \,\, I_L$ & $\kappa_l \cdot \pi_l(u)$ & $S$ & $\rightarrow$ & $u \,\, I_S \,\, v$ & $\kappa_s \cdot \pi_s(uv)$ \\ \hline
    & $|$ & $B$ & $\kappa_l \cdot \pi_l(S)$ & & $|$ & $B_e$ & $1-\kappa_s$ \\ \hline
    & $|$ & $\Send$ & $1-\kappa_l$ & & & & \\ \hline
    $I_L$ & $\rightarrow$ & $u \, \, I_L$ & $\kappa_l \cdot \pi_l(u)$ & $I_S$ & $\rightarrow$ & $u \,\, I_S \,\, v$ & $\kappa_s \cdot \pi_s(uv)$\\ \hline
    & $|$ & $B$ & $\kappa_l \cdot \pi_l(S)$ & & $|$ & $B_e$ & $1-\kappa_s$\\ \hline
    & $|$ & $\Send$ & $1-\kappa_l$ & & & & \\ \hline \hline
    $B$ & $\rightarrow$ & $(L \,\, S)$ & 1 & & & & \\ \hline
    $B_e$ & $\rightarrow$ & $(L \,\, \Send)$ & 1 & & & & \\ \hline
  \end{tabular}
  \begin{flushleft}
    The state types for this model are shown in
    \tabref{tkfstsinglet-types}.  The singlet transducer generates
    ancestral RNA sequences and structures.  We use the notation of
    formal grammars to represent state transformation rules; for
    example, the rule $I_L \rightarrow u\,\,I_L$ corresponds to (in a
    Pair HMM) an $\Sinsert$ state $I_L$ emitting a nucleotide $u$ and
    then making a self-transition.  Both loop ($L$ and $I_L$) and stem
    ($S$ and $I_S$) sequence evolve as TKF sequences with length
    parameters $\kappa_l$ and $\kappa_s$ (defined in \secname{A simple model
    of RNA structural evolution}).  $\pi_l(u)$ and $\pi_s(uv)$ are
    the equilibrium distributions of unpaired nucleotides $u$ and
    paired nucleotides $(u,v)$ and are normalized such that
    $\pi_l(S) + \sum_u \pi_l(u) = 1$ and $\sum_{u,v} \pi_s(uv) = 1$.  The bifurcation state $B_e$ is used
    to end stem sequences (only loop sequences are allowed to
    transition to the empty string).
  \end{flushleft}
  \tablabel{tkfstsinglet}
\end{table}

\begin{table}[!ht]
  \caption{
    \textbf{State types of the branch transducer
      (conditionally-normalized Pair SCFG) of the TKF Structure Tree
      model.}}
  \begin{tabular}{|l|rrrl|} \hline
    State & $\type$ & $\absorb$ & $\emit$ & description \\ \hline
    $L$ & $\Sstart$ & & & Start of a loop \\ \hline
    $I_L$ & $\Sinsert$ & & $(u,\Tnull)$ & Single-base insertion \\ \hline
    $M_L$ & $\Smatch$ & $(x,\Tnull)$ & $(u,\Tnull)$ & Single-base substitution \\ \hline
    $D_L$ & $\Smatch$ & $(x,\Tnull)$ & & Single-base deletion \\ \hline
    $W_L$ & $\Swait$ & & & Wait for next base \\ \hline \hline
    $S$ & $\Sstart$ & & & Start of a stem \\ \hline
    $I_S$ & $\Sinsert$ & & $(u,v)$ & Base-pair insertion \\ \hline
    $M_S$ & $\Smatch$ & $(x,y)$ & $(u,v)$ & Base-pair substitution \\ \hline
    $D_S$ & $\Smatch$ & $(x,y)$ & & Base-pair deletion \\ \hline
    $W_S$ & $\Swait$ & & & Wait for next base-pair \\ \hline \hline
    $B_i$ & $\Sinsert$ & & $(L_i\,S_i)$ & Stem insertion \\ \hline
    $B$ & $\Smatch$ & $(L\,S)$ & $(L\,S)$ & Stem conservation \\ \hline
    $B_p$ & $\Smatch$ & $(L\,S)$ & $(L\,\Send)$ & Stem deletion \\ \hline
    $B_e$ & $\Smatch$ & $(L\,\Send)$ & $(L\,\Send)$ & Stem extinction \\ \hline
  \end{tabular}
  \begin{flushleft}
    States which have the same names as states of the singlet transducer in \tabref{tkfstsinglet-types}
    are the branch-transducer equivalents of the corresponding singlet-transducer states
    (e.g., a $\Smatch$ state might be the branch equivalent of an $\Sinsert$ state).
    States $L_i$ and $S_i$ are the $\Sstart$ states of a sub-model (not shown) identical
    in structure to the singlet transducer.  They are used to insert a
    new stem-loop structure.
  \end{flushleft}
  \tablabel{tkfstbranch-types}
\end{table}

% Use table to allow the table to span the width of the entire page.
\begin{table}[!ht]
  \caption{
    \textbf{Branch transducer (conditionally-normalized Pair SCFG) of
      the TKF Structure Tree model.}}
  \begin{tabular}{|rcl|r||rcl|r|} \hline
    Source & $\rightarrow$ & Destination & probability & Source & $\rightarrow$ & Destination & probability \\ \hline
    $L$ & $\rightarrow$ & $w \,\, I_L$ & $\beta_l(t) \cdot \pi_l(w)$ & $S$ & $\rightarrow$ & $w \,\, I_S \,\, x$ & $\beta_s(t) \cdot \pi_s(wx)$ \\ \hline
    & $|$ & $B_i$ & $\beta_l(t) \cdot \pi_l(S)$ & & $|$ & $W_S$ & $1-\beta_s(t)$ \\ \hline
    & $|$ & $W_L$ & $1-\beta_l(t)$ & & & &  \\ \hline
    $I_L$ & $\rightarrow$ & $w \,\, I_L$ & $\beta_l(t) \cdot \pi_l(w)$ & $I_S$ & $\rightarrow$ & $w \,\, I_S \,\, x$ & $\beta_s(t) \cdot \pi_s(wx)$ \\ \hline
    & $|$ & $B_i$ & $\beta_l(t) \cdot \pi_l(S)$ & & $|$ & $W_S$ & $1-\beta_s(t)$ \\ \hline
    & $|$ & $W_L$ & $1-\beta_l(t)$ & & & & \\ \hline
    $M_L$ & $\rightarrow$ & $w \,\, I_L$ & $\beta_l(t) \cdot \pi_l(w)$ & $M_S$ & $\rightarrow$ & $w \,\, I_S \,\, x$ & $\beta_s(t) \cdot \pi_s(wx)$ \\ \hline
    & $|$ & $B_i$ & $\beta_l(t) \cdot \pi_l(S)$ & & $|$ & $W_S$ & $1-\beta_s(t)$ \\ \hline
    & $|$ & $W_L$ & $1-\beta_l(t)$ & & & &  \\ \hline
    $D_L$ & $\rightarrow$ & $w \,\, I_L$ & $\gamma_l(t) \cdot \pi_l(w)$ & $D_S$ & $\rightarrow$ & $w \,\, I_S \,\, x$ & $\gamma_s(t) \cdot \pi_s(wx)$ \\ \hline
    & $|$ & $B_i$ & $\gamma_l(t) \cdot \pi_l(S)$ & & $|$ & $W_S$ & $1-\gamma_s(t)$ \\ \hline
    & $|$ & $W_L$ & $1-\gamma_l(t)$ & & & &  \\ \hline
    $W_L$ & $\rightarrow$ & $w \,\, M_L$ & $\alpha_l(t) \cdot M_l(u \rightarrow w)$ & $W_S$ & $\rightarrow$ & $w \,\, M_S \,\, x$ & $\alpha_s(t) \cdot M_s(uv \rightarrow wx)$ \\ \hline
    & $|$ & $D_L$ & $1-\alpha_l(t)$ & & $|$ & $D_S$ & $1-\alpha_s(t)$ \\ \hline
    & $|$ & $B$ & $\alpha_l(t)$ & & $|$ & $B_e$ & $1$ \\ \hline
    & $|$ & $B_p$ & $1-\alpha_l(t)$ & & & &  \\ \hline
    & $|$ & $\Send$ & $1$ & & & &  \\ \hline \hline
    $B$ & $\rightarrow$ & $L \,\, S$ & 1 & $B_p$ & $\rightarrow$ & $L \, \, \Send$ & 1 \\ \hline
    $B_i$ & $\rightarrow$ & $L_i \,\, S_i$ & 1 & $B_e$ & $\rightarrow$ & $L \, \, \Send$ & 1 \\ \hline \hline
  \end{tabular}
  \begin{flushleft}
    The state types for this model are shown in
    \tabref{tkfstbranch-types}. The branch transducer evolves a
    sequence and structure along a branch of the phylogenetic
    tree. States $L_i$ and $S_i$ are the $\Sstart$ states for a
    sub-model corresponding to an insertion of a new stem in the
    descendant sequences; the sub-model (not shown) is identical in
    structure to the singlet transducer shown in
    \tabref{tkfstsinglet}. $\pi_l(w)$ and $\pi_s(wx)$ are the
    equilibrium distributions of, respectively, descendant unpaired
    nucleotide $w$ and descendant paired nucleotides $(w,x)$;
    $M_l(u \rightarrow w)$ and $M_l(uv \rightarrow wx)$ are the conditional distributions
    (i.e., match probabilities) of a descendant unpaired
    nucleotide $w$ given an ancestral unpaired nucleotide $u$ and
    descendant paired nucleotides $(w,x)$ given ancestral nucleotides
    $(u,v)$. The functions $\alpha_{l,s}(t)$, $\beta_{l,s}(t)$ and
    $\gamma_{l,s}(t)$ are parametrized by the insertion and deletion rates
    of the TKFST model and are defined in \secname{A simple model of RNA
    structural evolution}.
  \end{flushleft}
  \tablabel{tkfstbranch}
\end{table}


% Tables created as follows:
% sort -k 1,2 bralibaseII.results | perl -pe 's/0\.(\d\d)(\d)\d+/$1.$2/g;s/ +/ & /g' | cols
% ...then manual editing

% Method                          & Metric      & U5   & g2intron & rRNA & tRNA & TPP_riboswitch
% stemloc.progressive             & Align_Sens  & 82.6 & 74.2     & 92.6 & 93.2 & 76.8          
% stemloc.progressive             & Align_ppv   & 83.7 & 74.8     & 92.8 & 93.9 & 80.7          
% stemloc.progressive             & Struct_Sens & 74.9 & 64.3     & 51.0 & 74.0 & 57.1          
% stemloc.progressive             & Struct_ppv  & 73.9 & 56.7     & 59.0 & 76.4 & 63.3          
% stemloc.progressive.xrate       & Align_Sens  & 82.6 & 74.2     & 92.6 & 93.2 & 76.8          
% stemloc.progressive.xrate       & Align_ppv   & 83.7 & 74.8     & 92.8 & 93.9 & 80.7          
% stemloc.progressive.xrate       & Struct_Sens & 90.5 & 88.2     & 77.2 & 88.5 & 72.3          
% stemloc.progressive.xrate       & Struct_ppv  & 66.2 & 63.2     & 64.4 & 70.6 & 74.7          
% stemloc.tkfst.progressive       & Align_Sens  & 81.6 & 75.4     & 91.4 & 94.6 & 62.4          
% stemloc.tkfst.progressive       & Align_ppv   & 81.7 & 75.0     & 92.6 & 94.4 & 73.7          
% stemloc.tkfst.progressive       & Struct_Sens & 37.9 & 42.1     & 37.4 & 70.9 & 36.2          
% stemloc.tkfst.progressive       & Struct_ppv  & 68.0 & 63.8     & 66.5 & 88.3 & 77.2          
% stemloc.tkfst.progressive.xrate & Align_Sens  & 81.6 & 75.4     & 91.4 & 94.6 & 62.4          
% stemloc.tkfst.progressive.xrate & Align_ppv   & 81.7 & 75.0     & 92.6 & 94.4 & 73.7          
% stemloc.tkfst.progressive.xrate & Struct_Sens & 80.8 & 84.5     & 80.6 & 88.6 & 59.8          
% stemloc.tkfst.progressive.xrate & Struct_ppv  & 60.7 & 64.1     & 66.9 & 71.1 & 63.9          

% We first modified \stemloc\ to allow the user to specify the Pair SCFG that it uses for progressive alignment.
% We then used our program \evoldoer, an implementation of TKFST for pairwise alignment,
% to generate Pair SCFGs corresponding to the TKFST model at timepoints $\{0.01,0.1,0.2,0.3,0.4\}$,
% using loop and stem substitution rate matrices estimated with \xrate\ from
% ribosomal RNA alignments \cite{DeRijkEtAl2001,DowellEddy2006}
% and TKFST parameters $\{\lambda_n,\mu_n\}$ estimated previously \cite{Holmes2004}.

\begin{table}[ht]
  \caption{
    \textbf{Percentage sensitivity and positive predictive value (Sensitivity / PPV) for pairwise nucleotide-level alignments in the \bralibaseII\ benchmark.}}
  \begin{tabular}{|r|rrrr|}
    \hline
    & U5                      & g2intron                & rRNA                    & tRNA \\
    \hline
    TKFST grammar     &      81.6  /      81.7  & {\bf 75.4} / {\bf
      75.0} &      91.4  /      92.6  & {\bf 94.6} / {\bf 94.4} \\ \hline
    \stemloc\ grammar & {\bf 82.6} / {\bf 83.7} &      74.2  /
    74.8  & {\bf 92.6} / {\bf 92.8} &      93.2  /      93.9 \\ \hline
    \end{tabular}
\begin{flushleft}
  We compared the performance of the TKFST model for progressive multiple alignment
  of RNAs against the performance of a grammar with a richer model of RNA structure (\stemloc\ \cite{Holmes2005}).
  Sensitivity is defined as $\mbox{TP}/(\mbox{TP} + \mbox{FN})$ and PPV is defined as $\mbox{TP}/(\mbox{TP} + \mbox{FP})$,
  where TP is the number of true positives (correctly aligned residue pairs),
  FN is the number of false negatives (residue pairs that should have been aligned but were not) and
  FP is the number of false positives (residue pairs that were incorrectly aligned).
  These statistics are summed over all pairs of sequences in the multiple alignment;
  therefore, ``Sensitivity'' for pairwise residue alignments is equivalent to the Sum of Pairs Score or SPS \cite{ThompsonEtal99}.
  ``g2intron'' is the RFAM entry {\tt Intron\_gpII}, containing domains V and VI of the Group II intron.
  \end{flushleft}
  \tablabel{bralibaseII-align}
\end{table}

\begin{table}[ht]
  \caption{
    \textbf{Percentage sensitivity and positive predictive value (Sensitivity / PPV) for predicted base-pairs in the \bralibaseII\ benchmark.}}
  \begin{tabular}{|r|rrrr|}
    \hline
    & U5                      & g2intron                & rRNA                    & tRNA \\
    \hline
    TKFST grammar      &      37.9  /      68.0   &      42.1  /
    63.8  &      37.4  /      66.5  &      70.9  / {\bf 88.3} \\ \hline
    \stemloc\ grammar  &      74.9  / {\bf 73.9}  &      64.3  /
    56.7  &      51.0  /      59.0  &      74.0  /      76.4  \\ \hline
  \end{tabular}
  \begin{flushleft}
    We compared the performance of the TKFST model for structure-prediction accuracy during
    progressive multiple alignment of RNAs against the performance of a grammar with 
    a richer model of RNA structure (\stemloc\ \cite{Holmes2005}).
    ``g2intron'' is the RFAM entry {\tt Intron\_gpII}, containing domains V and VI of the Group II intron.
  \end{flushleft}
  \tablabel{bralibaseII-struct}
\end{table}





% nanos: Counted 3672701 subseqs and 48323860 bifurcations.
% tRNA: Counted 12573792 subseqs and 404730480 bifurcations.
% Y: Counted 34474759 subseqs and 1429713088 bifurcations.
% g2intron: Counted 139037184 subseqs and 1895528744 bifurcations.
% Scaling constant is approximately
% A * (404730480 / 48323860) = (19 / 3) => A = 0.76
% time = A * (# bifs / # bifs for nanos) * time for nanos
% Y time = 0.76 * (1429713088 / 48323860) * 3 min = 67 min
% g2intron time = 0.76 * (1895528744 / 48323860) * 3 min = 89 min
\begin{table}[!ht]
  \caption{
   \textbf{Estimates of the memory and time required to reconstruct ancestral
     structures of three RNAs from several families of biological interest
     (as reported by \indiegram).}}
 \begin{tabular}{|l|rrr|} \hline
    Family & Sequence lengths & Memory & Time \\ \hline
    \emph{nanos} 3' TCE & 61-64 nt & 3 Gb & 3 min \\ \hline
    tRNA & 69-73 nt & 11 Gb & 19 min \\ \hline
    Y RNA & 47-81 nt & 33 Gb & 70 min \\ \hline
    Group II intron (domains V and VI) & 76-91 nt & 122 Gb & 90 min \\ \hline
  \end{tabular}
  \begin{flushleft}
    The \emph{nanos} 3' translational control element (TCE) sequences
    are the seed sequences of the
    corresponding RFAM family \cite{GriffithsJonesEtAl2003} and the
    three tRNA sequences are from the \bralibaseII\ database
    \cite{GardnerEtAl2005} (identifiers AB042432.1-14140\_14072,
    Z82044.1-16031\_16103 and AC008670.6-83725\_83795). The group II
    intron sequences (identifiers Z00044.1-87253\_87177,
    X57546.1-2817\_2907 and X04465.1-2700\_2775) are from BralibaseII
    \cite{GardnerEtAl2005}.  The Y RNAs are hY1, hY4, and hY5 from
    \cite{TeunissenEtAl2000}; sequence lengths exclude the conserved
    stem S1.  The time estimates are for a 2.2GHz AMD Opteron 848 CPU.
  \end{flushleft}
  \tablabel{complexities}
\end{table}


\clearpage
\section*{Algorithms}


\begin{algorithm}[!ht]

  \SetKwData{bifurcProb}{bifurcProb}
  \SetKwFunction{calcTransEmitProb}{calcTransEmitProb}
  \SetKwFunction{calcLBifurcProb}{calcLBifurcProb}
  \SetKwFunction{calcRBifurcProb}{calcRBifurcProb}
  \SetLine
  \KwIn{sequences $X, Y, Z$}

  \ForEach(\tcc*[f]{inside-outside sorted}){$n^{(X)} \in \foldenv^{(X)}$} {
    \ForEach(\tcc*[f]{inside-outside sorted}){$n^{(Y)} \in \foldenv^{(Y)}$} {
      \ForEach(\tcc*[f]{inside-outside sorted}){$n^{(Z)} \in \foldenv^{(Z)}$} {
        \BlankLine
        \ForEach{state $\bvec{a}$}{
          \BlankLine
          \bifurcProb $\leftarrow 0$\;
          \ForEach{$\left( n^{(X)}_L,n^{(X)}_R \right) \in b_{in}\left( n^{(X)} \right)$} {
            \ForEach{$\left( n^{(Y)}_L,n^{(Y)}_R \right) \in b_{in}\left( n^{(Y)} \right)$} {
              \ForEach{$\left( n^{(Z)}_L,n^{(Z)}_R \right) \in b_{in}\left( n^{(Z)} \right)$} {
                \bifurcProb += \calcLBifurcProb($\bvec{a}; \cdot$)\;
                \bifurcProb += \calcRBifurcProb($\bvec{a}; \cdot$)\;
              }
            }
          }
          \BlankLine
          $\alpha_{\bvec{a}} \left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$ $\leftarrow$ \calcTransEmitProb$\left( \bvec{a}; n^{(X)}, n^{(Y)}, n^{(Z)} \right)$\;
          $\alpha_{\bvec{a}} \left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$ += \bifurcProb\;
          store $\alpha_{\bvec{a}} \left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$\;
        }
        \BlankLine
      }
    }
  }
  \KwRet{$\alpha_{\bvec{a}}\left( n^{(X)}[0,L^{(X)}],n^{(Y)}[0,L^{(Y)}],n^{(Z)}[0,L^{(Z)}] \right)$}\;
  
  \caption{\alglabel{inside}
    The constrained Inside algorithm for three sequences $X, Y, Z$.
    Ensemble states $\bvec{a}$ in the iteration over states are sorted in Inside fill order
    with $\Semit$ states first, then $\Snull$ states in reverse topological order.
  }
\end{algorithm}

\begin{algorithm}[!ht]
  \SetKwData{emitProb}{emitProb}
  \SetLine
  \KwIn{state $\bvec{a}, n^{(X)}, n^{(Y)}, n^{(Z)}$, intermediate Inside matrix $\alpha$}

  \emitProb $\leftarrow 0$\;
  \ForEach{$\bvec{b} : \exists \,\bvec{a} \to \bvec{b}$} {
    \emitProb += $P \left( \bvec{a} \to \bvec{b} \right)\, \alpha_{\bvec{b}}\left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$\;
  }
  \ForEach{$\bvec{b} : \exists \,\bvec{a} \to \bvec{l}\,\bvec{b}\,\bvec{r}$} {
    \lIf{$c_{in}\left(\bvec{b}; n^{(X)}\right) \notin \foldenv^{(X)}$ or $c_{in}\left(\bvec{b}; n^{(Y)}\right) \notin \foldenv^{(Y)}$ or $c_{in}\left(\bvec{b}; n^{(Z)}\right) \notin \foldenv^{(Z)}$}{next\;}
    \emitProb += $P \left( \bvec{a} \to \bvec{l}\,\bvec{b}\,\bvec{r} \right)\, \alpha_{\bvec{b}}\left( c_{in}\left(\bvec{b}; n^{(X)}\right), c_{in}\left(\bvec{b}; n^{(Y)}\right), c_{in}\left(\bvec{b}; n^{(Z)}\right) \right)$\;
  }
  \KwRet{\emitProb}\;
  \caption{\alglabel{insidetransemit}
    Subroutine $\mathrm{calcTransEmitProb}()$ for the Inside algorithm.
    $\bvec{a}$ and $\bvec{b}$ are ensemble states; $\bvec{l}$ and $\bvec{r}$ are left and right terminal emissions.
  }
\end{algorithm}

\begin{algorithm}[!ht]

  \SetKwData{maxProb}{maxProb}
  \SetKwData{bifurcProb}{bifurcProb}
  \SetKwFunction{calcTransEmitProb}{calcTransEmitProb}
  \SetKwFunction{calcLBifurcProb}{calcLBifurcProb}
  \SetKwFunction{calcRBifurcProb}{calcRBifurcProb}
  \SetLine
  \KwIn{sequences $X, Y, Z$}

  \ForEach(\tcc*[f]{inside-outside sorted}){$n^{(X)} \in \foldenv^{(X)}$} {
    \ForEach(\tcc*[f]{inside-outside sorted}){$n^{(Y)} \in \foldenv^{(Y)}$} {
      \ForEach(\tcc*[f]{inside-outside sorted}){$n^{(Z)} \in \foldenv^{(Z)}$} {
        \BlankLine
        \ForEach{state $\bvec{a}$}{
          \BlankLine
          \bifurcProb $\leftarrow 0$\;
          \ForEach{$\left( n^{(X)}_L,n^{(X)}_R \right) \in b_{in}\left( n^{(X)} \right)$} {
            \ForEach{$\left( n^{(Y)}_L,n^{(Y)}_R \right) \in b_{in}\left( n^{(Y)} \right)$} {
              \ForEach{$\left( n^{(Z)}_L,n^{(Z)}_R \right) \in b_{in}\left( n^{(Z)} \right)$} {
                \bifurcProb += \calcLBifurcProb($\bvec{a}; \cdot$)\;
                \bifurcProb += \calcRBifurcProb($\bvec{a}; \cdot$)\;
              }
            }
          }
          \BlankLine
          $\gamma_{\bvec{a}} \left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$ \\
          $\qquad \leftarrow \max \left( \calcTransEmitProb \left( \bvec{a}; n^{(X)}, n^{(Y)}, n^{(Z)} \right), \bifurcProb \right)$ \;
          store $\gamma_{\bvec{a}} \left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$\;
        }
        \BlankLine
      }
    }
  }
  \KwRet{$\gamma_{\bvec{a}}\left( n^{(X)}[0,L^{(X)}],n^{(Y)}[0,L^{(Y)}],n^{(Z)}[0,L^{(Z)}] \right)$}\;
  
  \caption{\alglabel{cyk}
    The constrained CYK algorithm for three sequences $X, Y, Z$.
    Ensemble states $\bvec{a}$ in the iteration over states are sorted in Inside fill order
    with $\Semit$ states first, then $\Snull$ states in reverse topological order.
  }
\end{algorithm}

\begin{algorithm}[!ht]
  \SetKwData{emitProb}{emitProb}
  \SetLine
  \KwIn{state $\bvec{a}, n^{(X)}, n^{(Y)}, n^{(Z)}$, intermediate CYK matrix $\gamma$}

  \emitProb $\leftarrow 0$\;
  \ForEach{$\bvec{b} : \exists \,\bvec{a} \to \bvec{b}$} {
    \emitProb = $\max \left( \emitProb, P \left( \bvec{a} \to \bvec{b} \right)\, \gamma_{\bvec{b}}\left( n^{(X)}, n^{(Y)}, n^{(Z)} \right) \right)$\;
  }
  \ForEach{$\bvec{b} : \exists \,\bvec{a} \to \bvec{l}\,\bvec{b}\,\bvec{r}$} {
    \lIf{$c_{in}\left(\bvec{b}; n^{(X)}\right) \notin \foldenv^{(X)}$ or $c_{in}\left(\bvec{b}; n^{(Y)}\right) \notin \foldenv^{(Y)}$ or $c_{in}\left(\bvec{b}; n^{(Z)}\right) \notin \foldenv^{(Z)}$}{next\;}
    \emitProb = $\max \left( \emitProb, P \left( \bvec{a} \to \bvec{l}\,\bvec{b}\,\bvec{r} \right)\, \gamma_{\bvec{b}}\left( c_{in}\left(\bvec{b}; n^{(X)}\right), c_{in}\left(\bvec{b}; n^{(Y)}\right), c_{in}\left(\bvec{b}; n^{(Z)}\right) \right) \right)$\;
  }
  \KwRet{\emitProb}\;
  \caption{\alglabel{cyktransemit}
    Subroutine $\mathrm{calcTransEmitProb}()$ for the CYK algorithm.
    $\bvec{a}$ and $\bvec{b}$ are ensemble states; $\bvec{l}$ and $\bvec{r}$ are left and right terminal emissions.
  }
\end{algorithm}


\begin{algorithm}[!ht]
  \SetKwFunction{calcTransEmitProb}{calcTransEmitProb}
  \SetKwData{bifurcProb}{bifurcProb}
  \SetKwFunction{calcLBifurcProb}{calcLBifurcProb}
  \SetKwFunction{calcRBifurcProb}{calcRBifurcProb}
  \SetLine
  \KwIn{sequences $X, Y, Z$, Inside matrix $\alpha$}

  \ForEach(\tcc*[f]{outside-inside sorted}){$n^{(X)} \in \foldenv^{(X)}$} {
    \ForEach(\tcc*[f]{outside-inside sorted}){$n^{(Y)} \in \foldenv^{(Y)}$} {
      \ForEach(\tcc*[f]{outside-inside sorted}){$n^{(Z)} \in \foldenv^{(Z)}$} {
        \BlankLine
        \ForEach{state $\bvec{b}$}{
          \BlankLine
          \bifurcProb $\leftarrow 0$\;
          \ForEach{$\left( n^{(X)}_O,n^{(X)}_L \right) \in b_{out,L}\left( n^{(X)} \right)$}{
            \ForEach{$\left( n^{(Y)}_O,n^{(Y)}_L \right) \in b_{out,L}\left( n^{(Y)} \right)$}{
              \ForEach{$\left( n^{(Z)}_O,n^{(Z)}_L \right) \in b_{out,L}\left( n^{(Z)} \right)$}{
                \bifurcProb += \calcLBifurcProb($\bvec{b}; \cdot$)\;
              }
            }
          }
          \ForEach{$\left( n^{(X)}_O,n^{(X)}_R \right) \in b_{out,R}\left( n^{(X)} \right)$}{
            \ForEach{$\left( n^{(Y)}_O,n^{(Y)}_R \right) \in b_{out,R}\left( n^{(Y)} \right)$}{
              \ForEach{$\left( n^{(Z)}_O,n^{(Z)}_R \right) \in b_{out,R}\left( n^{(Z)} \right)$}{
                \bifurcProb += \calcRBifurcProb($\bvec{b}; \cdot$)\;
              }
            }
          }
          \BlankLine
          $\beta_{\bvec{b}} \left( n^{(X)}, n^{(Y)}, n^{(Z)} \right) \leftarrow$ \calcTransEmitProb$\left( \bvec{b}; n^{(X)}, n^{(Y)}, n^{(Z)} \right)$\;
          $\beta_{\bvec{b}} \left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$ += \bifurcProb\;
          store $\beta_{\bvec{b}} \left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$\;
        }
        \BlankLine
      }
    }
  }
  \caption{\alglabel{outside}
    The constrained Outside algorithm for three sequences $X, Y, Z$.
    Ensemble states $\bvec{a}$ in the iteration over states are sorted in Outside fill order
    with $\Semit$ states first, then $\Snull$ states in topological order.
  }
\end{algorithm}

\begin{algorithm}[!ht]
  \SetKwData{emitProb}{emitProb}
  \SetLine
  \KwIn{state $\bvec{b}, n^{(X)}, n^{(Y)}, n^{(Z)}$, intermediate Outside matrix $\beta$}

  \emitProb $\leftarrow 0$\;
  \ForEach{$\bvec{a} : \exists \,\bvec{a} \to \bvec{b}$} {
    \emitProb += $P \left( \bvec{a} \to \bvec{b} \right)\, \beta_{\bvec{a}}\left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$\;
  }
  \ForEach{$\bvec{a} : \exists \,\bvec{a} \to \bvec{l}\,\bvec{b}\,\bvec{r}$} {
    \lIf{$c_{out}\left(\bvec{b}; n^{(X)}\right) \notin \foldenv^{(X)}$ or $c_{out}\left(\bvec{b}; n^{(Y)}\right) \notin \foldenv^{(Y)}$ or $c_{out}\left(\bvec{b}; n^{(Z)}\right) \notin \foldenv^{(Z)}$}{next\;}
    \emitProb += $P \left( \bvec{a} \to \bvec{l}\,\bvec{b}\,\bvec{r} \right)\, \beta_{\bvec{a}}\left( c_{out}\left(\bvec{b}; n^{(X)}\right), c_{out}\left(\bvec{b}; n^{(Y)}\right), c_{out}\left(\bvec{b}; n^{(Z)}\right) \right)$\;
  }
  \KwRet{\emitProb}\;
  \caption{\alglabel{outsidetransemit}
    Subroutine $\mathrm{calcTransEmitProb}()$ for the Outside algorithm.
    $\bvec{a}$ and $\bvec{b}$ are ensemble states; $\bvec{l}$ and $\bvec{r}$ are left and right terminal emissions.
  }
\end{algorithm}

\begin{algorithm}[!ht]

  \SetKw{Select}{select}
  \SetKw{Pop}{pop}
  \SetKw{Push}{push}
  \SetKw{Goto}{goto}
  \SetKw{Mainloop}{main loop}
  \SetKwData{coordinateStack}{coordinateStack}
  \SetKwFunction{goto}{goto}
  \SetKwBlock{Begin}{begin main loop:}{end}
  \SetLine
  \KwIn{sequences $X, Y, Z$}

  pushdown stack coordinateStack; \tcc*[f]{hold (state, subsequence triplet) pairs} \\
  $\bvec{a} \leftarrow \Sstart$; \tcc*[f]{current ensemble state} \\
  $n^{(X)} \leftarrow N^{(X)}$; \tcc*[f]{current $X$ subsequence; $N^{(X)}$ is the outermost subsequence} \\
  $n^{(Y)} \leftarrow N^{(Y)}$; \tcc*[f]{current $Y$ subsequence; $N^{(Y)}$ is the outermost subsequence} \\
  $n^{(Z)} \leftarrow N^{(Z)}$; \tcc*[f]{current $Z$ subsequence; $N^{(Z)}$ is the outermost subsequence} \\
  clear \coordinateStack;\

  \Begin{
    output current state $\bvec{a}$ and subsequence triplet $\left( n^{(X)}, n^{(Y)}, n^{(Z)} \right)$\;
    \SetLine
    \uIf(\tcc*[f]{end of a parse subtree}){$\bvec{a}$ is the $\Send$ state}{
      \lIf(\tcc*[f]{end of the parse tree}){\coordinateStack is empty}{\Return}
      \Pop $\left( \bvec{a}, n^{(X)}, n^{(Y)}, n^{(Z)} \right)$ from \coordinateStack\;
      \Goto \Mainloop\;
    }
    \uElseIf(\tcc*[f]{bifurcation $\bvec{a} \to \bvec{c} \bvec{b}$}){$\bvec{a}$ is a bifurcation state}{
      \Select $\left( n^{(X)}_L, n^{(X)}_R \right) \in b_{in}\left( n^{(X)} \right)$,
      $\left( n^{(Y)}_L, n^{(Y)}_R \right) \in b_{in}\left( n^{(Y)} \right)$,
      $\left( n^{(Z)}_L, n^{(Z)}_R \right) \in b_{in}\left( n^{(Z)} \right)$ \\
      such that \\
      $\gamma_{\bvec{a}} \left(n^{(X)}, n^{(Y)}, n^{(Z)} \right) = \gamma_{\bvec{a}} \left(n^{(X)}_L, n^{(Y)}_L, n^{(Z)}_L \right)  \gamma_{\bvec{a}} \left(n^{(X)}_R, n^{(Y)}_R, n^{(Z)}_R \right)$ \;
      \Push $\left( \bvec{c}, n^{(X)}_R, n^{(Y)}_R, n^{(Z)}_R \right)$ onto \coordinateStack\;
      $\bvec{a} \leftarrow \bvec{b}$\;
      $n^{(X)} \leftarrow n^{(X)}_L$\;
      $n^{(Y)} \leftarrow n^{(Y)}_L$\;
      $n^{(Z)} \leftarrow n^{(Z)}_L$\;
      \Goto \Mainloop\;
    }
    \Else(\tcc*[f]{$\Semit$ or $\Snull$ state}){
      $m^{(X)} \leftarrow c_{in}\left(\bvec{b}; n^{(X)}\right)$ \;
      $m^{(Y)} \leftarrow c_{in}\left(\bvec{b}; n^{(Y)}\right)$ \;
      $m^{(Z)} \leftarrow c_{in}\left(\bvec{b}; n^{(Z)}\right)$ \;
      \Select $\bvec{b} \in \left\{ b : \exists \,\bvec{a} \to \bvec{l}\bvec{b}\bvec{r} \right\}$ \\
      such that \\
      $\gamma_{\bvec{a}} \left( n^{(X)}, n^{(Y)}, n^{(Z)} \right) = P(\bvec{a} \to \bvec{l}\bvec{b}\bvec{r}) \gamma_{\bvec{b}} \left( m^{(X)}, m^{(Y)}, m^{(Z)} \right)$\;
      $\bvec{a} \leftarrow \bvec{b}$\;
      $n^{(X)} \leftarrow m^{(X)}$\;
      $n^{(Y)} \leftarrow m^{(Y)}$\;
      $n^{(Z)} \leftarrow m^{(Z)}$\;
      \Goto \Mainloop\;
    }
  }
  \caption{\alglabel{cyktraceback}
    The constrained CYK traceback algorithm for three sequences $X, Y, Z$.
  }
\end{algorithm}





\end{document}

